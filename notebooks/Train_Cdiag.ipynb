{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YrhYk2bxB_Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd678850-79fe-4d80-89cb-4998db220518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Navigate to your project directory in Google Drive\n",
        "%cd /content/drive/MyDrive/CAF-GAN/\n",
        "\n",
        "# Unzip the image files (this might take a few minutes)\n",
        "# The -q makes the output quiet, -n prevents unzipping if already done\n",
        "!unzip -q -n mimic-cxr-jpg-2.0.0.zip\n",
        "\n",
        "print(\"âœ… Workspace ready and images unzipped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaXxPXf_CZ0A",
        "outputId": "3cc4ef0e-5d4a-458e-a0f9-7dcf3009b451"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CAF-GAN\n",
            "âœ… Workspace ready and images unzipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml pandas scikit-learn albumentations segmentation-models-pytorch -q"
      ],
      "metadata": {
        "id": "d8VZ0P_1C4Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4608f28-b288-4e38-e33c-4973b9a56ab8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# This single dataset file will serve both critic training scripts.\n",
        "\n",
        "class MIMICCXRClassifierDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for the Cdiag (classification) task.\n",
        "    - Loads a JPG image.\n",
        "    - Converts it to RGB (as required by ResNet).\n",
        "    - Returns the image and its corresponding Pneumonia label.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        subject_id = str(row['subject_id'])\n",
        "        study_id = str(row['study_id'])\n",
        "        dicom_id = row['dicom_id']\n",
        "\n",
        "        # Construct the path to the JPG image\n",
        "        image_path = os.path.join(\n",
        "            self.image_dir, f'p{subject_id[:2]}', f'p{subject_id}', f's{study_id}', f'{dicom_id}.jpg'\n",
        "        )\n",
        "\n",
        "        # Load image and convert to a numpy array in RGB format\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = np.array(image)\n",
        "\n",
        "        # Apply augmentations\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        # Get the label\n",
        "        label = torch.tensor(row['Pneumonia'], dtype=torch.float32)\n",
        "\n",
        "        return image, label.unsqueeze(0)\n",
        "\n",
        "\n",
        "class MIMICXRSegmentationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for the Cseg (segmentation) task.\n",
        "    - Loads a JPG image (as grayscale).\n",
        "    - Loads its corresponding pre-generated PNG mask.\n",
        "    - Returns both the image and the mask.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, image_dir, mask_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        subject_id = str(row['subject_id'])\n",
        "        study_id = str(row['study_id'])\n",
        "        dicom_id = row['dicom_id']\n",
        "\n",
        "        # Construct paths for both image and mask\n",
        "        image_path = os.path.join(\n",
        "            self.image_dir, f'p{subject_id[:2]}', f'p{subject_id}', f's{study_id}', f'{dicom_id}.jpg'\n",
        "        )\n",
        "        mask_path = os.path.join(self.mask_dir, f\"{dicom_id}.png\")\n",
        "\n",
        "        # Load image and mask as grayscale numpy arrays\n",
        "        image = np.array(Image.open(image_path).convert(\"L\"), dtype=np.float32)\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
        "\n",
        "        # Normalize mask values from [0, 255] to [0.0, 1.0]\n",
        "        mask[mask == 255.0] = 1.0\n",
        "\n",
        "        # Apply augmentations (Albumentations will transform both identically)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        # Add a channel dimension for the mask for consistency\n",
        "        return image, mask.unsqueeze(0)"
      ],
      "metadata": {
        "id": "rDVWP3_8C-gw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Notice the paths now point to our Colab workspace in Google Drive\n",
        "config_yaml = \"\"\"\n",
        "# Configuration for training the Cdiag (Pneumonia Classifier) model\n",
        "\n",
        "# --- Data Paths ---\n",
        "IMAGE_DIR: \"/content/drive/MyDrive/CAF-GAN/mimic-cxr-jpg-2.0.0/files/\"\n",
        "TRAIN_CSV_PATH: \"/content/drive/MyDrive/CAF-GAN/data/splits/train.csv\"\n",
        "VAL_CSV_PATH: \"/content/drive/MyDrive/CAF-GAN/data/splits/val.csv\"\n",
        "\n",
        "# --- Output Paths ---\n",
        "OUTPUT_DIR: \"/content/drive/MyDrive/CAF-GAN/outputs/cdiag/\"\n",
        "MODEL_NAME: \"best_cdiag_colab.pth\"\n",
        "\n",
        "# --- Model & Training Hyperparameters ---\n",
        "IMG_SIZE: 256\n",
        "BATCH_SIZE: 32  # We can use a larger batch size on a Colab GPU\n",
        "EPOCHS: 20\n",
        "LEARNING_RATE: 0.0001\n",
        "\n",
        "# --- System ---\n",
        "DEVICE: \"cuda\"\n",
        "NUM_WORKERS: 2\n",
        "\"\"\"\n",
        "\n",
        "CONFIG = yaml.safe_load(config_yaml)\n",
        "print(\"Configuration loaded:\")\n",
        "print(CONFIG)"
      ],
      "metadata": {
        "id": "87Yg_DB4DIR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ea0eb8-8aaa-42a2-c079-c4837185f9d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded:\n",
            "{'IMAGE_DIR': '/content/drive/MyDrive/CAF-GAN/mimic-cxr-jpg-2.0.0/files/', 'TRAIN_CSV_PATH': '/content/drive/MyDrive/CAF-GAN/data/splits/train.csv', 'VAL_CSV_PATH': '/content/drive/MyDrive/CAF-GAN/data/splits/val.csv', 'OUTPUT_DIR': '/content/drive/MyDrive/CAF-GAN/outputs/cdiag/', 'MODEL_NAME': 'best_cdiag_colab.pth', 'IMG_SIZE': 256, 'BATCH_SIZE': 32, 'EPOCHS': 20, 'LEARNING_RATE': 0.0001, 'DEVICE': 'cuda', 'NUM_WORKERS': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.models as models\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "# The dataset classes are already defined in a previous cell\n",
        "\n",
        "# --- âš™ï¸ Setup ---\n",
        "# The CONFIG dictionary is already loaded from the previous cell\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "os.makedirs(CONFIG['OUTPUT_DIR'], exist_ok=True)\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# --- ðŸ‹ï¸â€â™€ï¸ Training & Validation Functions ---\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    return running_loss / len(dataloader.dataset)\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"Validating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct_preds += (preds == labels).sum().item()\n",
        "\n",
        "    val_loss = running_loss / len(dataloader.dataset)\n",
        "    val_acc = correct_preds / len(dataloader.dataset)\n",
        "    return val_loss, val_acc\n",
        "\n",
        "# --- ðŸš€ Main Execution ---\n",
        "def run_training():\n",
        "    # --- Data Loading & Augmentation ---\n",
        "    train_transform = A.Compose([\n",
        "        A.Resize(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=15, p=0.7),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    val_transform = A.Compose([\n",
        "        A.Resize(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    train_df = pd.read_csv(CONFIG['TRAIN_CSV_PATH'])\n",
        "    val_df = pd.read_csv(CONFIG['VAL_CSV_PATH'])\n",
        "\n",
        "    train_dataset = MIMICCXRClassifierDataset(train_df, CONFIG['IMAGE_DIR'], transform=train_transform)\n",
        "    val_dataset = MIMICCXRClassifierDataset(val_df, CONFIG['IMAGE_DIR'], transform=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=CONFIG['NUM_WORKERS'])\n",
        "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=CONFIG['NUM_WORKERS'])\n",
        "\n",
        "    # --- Model Setup ---\n",
        "    model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "    model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['LEARNING_RATE'])\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    for epoch in range(CONFIG['EPOCHS']):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{CONFIG['EPOCHS']} ---\")\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            model_path = os.path.join(CONFIG['OUTPUT_DIR'], CONFIG['MODEL_NAME'])\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\"âœ¨ New best model saved to {model_path}\")\n",
        "\n",
        "    print(\"\\nâœ… Training of Cdiag complete!\")\n",
        "\n",
        "# Run the training process\n",
        "run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LRfvu61DWoV",
        "outputId": "a8d5de4a-8598-418c-a4fd-3ea1fe6411a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 195MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 1/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [07:31<00:00, 10.26s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:43<00:00, 10.33s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3128 | Val Loss: 0.2680 | Val Accuracy: 0.9267\n",
            "âœ¨ New best model saved to /content/drive/MyDrive/CAF-GAN/outputs/cdiag/best_cdiag_colab.pth\n",
            "\n",
            "--- Epoch 2/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:42<00:00,  2.34s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.35s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2533 | Val Loss: 0.2825 | Val Accuracy: 0.9267\n",
            "\n",
            "--- Epoch 3/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:49<00:00,  2.48s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.21s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2382 | Val Loss: 0.2708 | Val Accuracy: 0.9267\n",
            "\n",
            "--- Epoch 4/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:47<00:00,  2.45s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.32s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2223 | Val Loss: 0.3013 | Val Accuracy: 0.9200\n",
            "\n",
            "--- Epoch 5/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:47<00:00,  2.43s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2030 | Val Loss: 0.3125 | Val Accuracy: 0.9167\n",
            "\n",
            "--- Epoch 6/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:47<00:00,  2.45s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.21s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1574 | Val Loss: 0.3392 | Val Accuracy: 0.8867\n",
            "\n",
            "--- Epoch 7/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:47<00:00,  2.44s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.26s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1486 | Val Loss: 0.4137 | Val Accuracy: 0.9267\n",
            "\n",
            "--- Epoch 8/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.46s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.32s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1253 | Val Loss: 0.3913 | Val Accuracy: 0.8800\n",
            "\n",
            "--- Epoch 9/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:47<00:00,  2.44s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.19s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1105 | Val Loss: 0.3559 | Val Accuracy: 0.8833\n",
            "\n",
            "--- Epoch 10/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.47s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.29s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0815 | Val Loss: 0.3524 | Val Accuracy: 0.9100\n",
            "\n",
            "--- Epoch 11/20 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:47<00:00,  2.43s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.33s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0667 | Val Loss: 0.4634 | Val Accuracy: 0.9233\n",
            "\n",
            "--- Epoch 12/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.46s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0695 | Val Loss: 0.3442 | Val Accuracy: 0.9067\n",
            "\n",
            "--- Epoch 13/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:49<00:00,  2.48s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0654 | Val Loss: 0.4252 | Val Accuracy: 0.9033\n",
            "\n",
            "--- Epoch 14/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.46s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0664 | Val Loss: 0.4165 | Val Accuracy: 0.8700\n",
            "\n",
            "--- Epoch 15/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.47s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0409 | Val Loss: 0.5628 | Val Accuracy: 0.9267\n",
            "\n",
            "--- Epoch 16/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.46s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0439 | Val Loss: 0.5902 | Val Accuracy: 0.9100\n",
            "\n",
            "--- Epoch 17/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.47s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0341 | Val Loss: 0.4515 | Val Accuracy: 0.8933\n",
            "\n",
            "--- Epoch 18/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:50<00:00,  2.51s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0259 | Val Loss: 0.4011 | Val Accuracy: 0.8467\n",
            "\n",
            "--- Epoch 19/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:50<00:00,  2.51s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0337 | Val Loss: 0.4309 | Val Accuracy: 0.9233\n",
            "\n",
            "--- Epoch 20/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [01:48<00:00,  2.46s/it]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0256 | Val Loss: 0.4076 | Val Accuracy: 0.8933\n",
            "\n",
            "âœ… Training of Cdiag complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}