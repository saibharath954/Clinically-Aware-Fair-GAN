{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml pandas scikit-learn albumentations segmentation-models-pytorch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration loaded for 512x512 Cdiag training.\n",
      "{'IMAGE_DIR': '/content/drive/MyDrive/CAF-GAN/mimic-cxr-jpg-2.0.0/files/', 'TRAIN_CSV_PATH': '/content/drive/MyDrive/CAF-GAN/data/splits/train.csv', 'VAL_CSV_PATH': '/content/drive/MyDrive/CAF-GAN/data/splits/val.csv', 'OUTPUT_DIR': '/content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/', 'MODEL_NAME': 'best_cdiag_512.pth', 'IMG_SIZE': 512, 'BATCH_SIZE': 16, 'EPOCHS': 20, 'LEARNING_RATE': 0.0001, 'DEVICE': 'cuda', 'NUM_WORKERS': 2}\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 133MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Resuming from checkpoint: /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/checkpoint.pth\n",
      "\n",
      "ğŸ‹ï¸â€â™€ï¸ Starting Cdiag training at epoch 15/20...\n",
      "\n",
      "--- Epoch 15/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [09:01<00:00,  6.16s/it]\n",
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [01:52<00:00,  5.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2936 | Val Loss: 0.9298 | Val Accuracy: 0.6233\n",
      "ğŸ’¾ Checkpoint saved at /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/checkpoint.pth (Epoch 15)\n",
      "\n",
      "--- Epoch 16/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [03:38<00:00,  2.48s/it]\n",
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:41<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2799 | Val Loss: 0.8145 | Val Accuracy: 0.6767\n",
      "ğŸ’¾ Checkpoint saved at /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/checkpoint.pth (Epoch 16)\n",
      "\n",
      "--- Epoch 17/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [03:34<00:00,  2.43s/it]\n",
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:41<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2222 | Val Loss: 0.8417 | Val Accuracy: 0.7567\n",
      "âœ¨ Best model updated: /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/best_cdiag_512.pth (Accuracy: 0.7567)\n",
      "ğŸ’¾ Checkpoint saved at /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/checkpoint.pth (Epoch 17)\n",
      "\n",
      "--- Epoch 18/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [03:37<00:00,  2.47s/it]\n",
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:41<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2161 | Val Loss: 0.7944 | Val Accuracy: 0.7033\n",
      "ğŸ’¾ Checkpoint saved at /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/checkpoint.pth (Epoch 18)\n",
      "\n",
      "--- Epoch 19/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [03:34<00:00,  2.44s/it]\n",
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:41<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1822 | Val Loss: 1.0991 | Val Accuracy: 0.6400\n",
      "ğŸ’¾ Checkpoint saved at /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/checkpoint.pth (Epoch 19)\n",
      "\n",
      "--- Epoch 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [03:36<00:00,  2.47s/it]\n",
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:41<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2119 | Val Loss: 0.9077 | Val Accuracy: 0.6500\n",
      "ğŸ’¾ Checkpoint saved at /content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/checkpoint.pth (Epoch 20)\n",
      "\n",
      "âœ… Training complete! Best validation accuracy: 0.7567\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Configuration (UPDATED FOR 512x512) ---\n",
    "CONFIG = {\n",
    "    \"IMAGE_DIR\": \"/content/drive/MyDrive/CAF-GAN/mimic-cxr-jpg-2.0.0/files/\",\n",
    "    \"TRAIN_CSV_PATH\": \"/content/drive/MyDrive/CAF-GAN/data/splits/train.csv\",\n",
    "    \"VAL_CSV_PATH\": \"/content/drive/MyDrive/CAF-GAN/data/splits/val.csv\",\n",
    "    \"OUTPUT_DIR\": \"/content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/\", # <-- New output dir\n",
    "    \"MODEL_NAME\": \"best_cdiag_512.pth\",                               # <-- New model name\n",
    "    \"IMG_SIZE\": 512,                                                 # <-- UPDATED resolution\n",
    "    \"BATCH_SIZE\": 16,        # <-- REDUCED batch size for larger images to prevent memory errors\n",
    "    \"EPOCHS\": 20,\n",
    "    \"LEARNING_RATE\": 1e-4,\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"NUM_WORKERS\": 2\n",
    "}\n",
    "print(\"âœ… Configuration loaded for 512x512 Cdiag training.\")\n",
    "print(CONFIG)\n",
    "\n",
    "# --- 2. PyTorch Dataset (MODIFIED FOR ROBUSTNESS) ---\n",
    "class MIMICCXRClassifierDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, img_size, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.img_size = img_size # Store image size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        subject_id, study_id, dicom_id = str(row['subject_id']), str(row['study_id']), row['dicom_id']\n",
    "\n",
    "        image_path = os.path.join(\n",
    "            self.image_dir, f'p{subject_id[:2]}', f'p{subject_id}', f's{study_id}', f'{dicom_id}.jpg'\n",
    "        )\n",
    "\n",
    "        # Load high-resolution image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # --- KEY CHANGE: Resize the image BEFORE converting to array and augmenting ---\n",
    "        image = image.resize((self.img_size, self.img_size), Image.LANCZOS)\n",
    "        image = np.array(image)\n",
    "        # -----------------------------------------------------------------------------\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        label = torch.tensor(row['Pneumonia'], dtype=torch.float32)\n",
    "\n",
    "        return image, label.unsqueeze(0)\n",
    "\n",
    "# --- 3. Training & Validation Functions (Unchanged) ---\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct_preds = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "    val_loss = running_loss / len(dataloader.dataset)\n",
    "    val_acc = correct_preds / len(dataloader.dataset)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# --- 4. Main Training Execution ---\n",
    "def run_training():\n",
    "    DEVICE = CONFIG['DEVICE']\n",
    "    os.makedirs(CONFIG['OUTPUT_DIR'], exist_ok=True)\n",
    "\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']), # Kept as a safeguard\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=15, p=0.7),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    train_df = pd.read_csv(CONFIG['TRAIN_CSV_PATH'])\n",
    "    val_df = pd.read_csv(CONFIG['VAL_CSV_PATH'])\n",
    "\n",
    "    # --- KEY CHANGE: Pass IMG_SIZE to the Dataset constructor ---\n",
    "    train_dataset = MIMICCXRClassifierDataset(train_df, CONFIG['IMAGE_DIR'], CONFIG['IMG_SIZE'], train_transform)\n",
    "    val_dataset = MIMICCXRClassifierDataset(val_df, CONFIG['IMAGE_DIR'], CONFIG['IMG_SIZE'], val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=CONFIG['NUM_WORKERS'])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=CONFIG['NUM_WORKERS'])\n",
    "\n",
    "    model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "    model.fc = nn.Linear(model.fc.in_features, 1) # Tailor for binary classification\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['LEARNING_RATE'])\n",
    "\n",
    "        # Resume if checkpoint exists\n",
    "    checkpoint_path = os.path.join(CONFIG['OUTPUT_DIR'], \"checkpoint.pth\")\n",
    "    start_epoch, best_val_acc = 0, 0.0\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"âœ… Resuming from checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_val_acc = checkpoint[\"best_val_acc\"]\n",
    "\n",
    "    print(f\"\\nğŸ‹ï¸â€â™€ï¸ Starting Cdiag training at epoch {start_epoch+1}/{CONFIG['EPOCHS']}...\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, CONFIG['EPOCHS']):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{CONFIG['EPOCHS']} ---\")\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_path = os.path.join(CONFIG['OUTPUT_DIR'], CONFIG['MODEL_NAME'])\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"âœ¨ Best model updated: {best_model_path} (Accuracy: {val_acc:.4f})\")\n",
    "\n",
    "        # Always save checkpoint\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"best_val_acc\": best_val_acc\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"ğŸ’¾ Checkpoint saved at {checkpoint_path} (Epoch {epoch+1})\")\n",
    "\n",
    "    print(f\"\\nâœ… Training complete! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "run_training()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
