{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrhYk2bxB_Yx",
        "outputId": "d743e048-3ce9-43a5-fa62-eb7790425b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d8VZ0P_1C4Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b517a4-a722-46c2-f2c4-ebb8e960fa72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml pandas scikit-learn albumentations segmentation-models-pytorch -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4fKBfR1xUI1",
        "outputId": "3e93b079-b251-43ba-e444-947dc8b128ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.models as models\n",
        "import torchvision.utils as vutils\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "import segmentation_models_pytorch as smp\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CONFIG: UPDATE THESE VALUES\n",
        "# -------------------------------------------------------------------\n",
        "CONFIG = {\n",
        "    # --- Paths ---\n",
        "    \"GENERATOR_CHECKPOINT\": \"/content/drive/MyDrive/CAF-GAN/outputs/caf_gan_final/caf_gan_generator_final.pth\",\n",
        "    \"CSEG_CHECKPOINT\": \"/content/drive/MyDrive/CAF-GAN/outputs/cseg_512/best_cseg_512.pth\",\n",
        "    \"REAL_DATA_CSV_TEST\": \"/content/drive/MyDrive/CAF-GAN/data/splits/test.csv\",\n",
        "    \"IMAGE_DIR_REAL\": \"/content/drive/MyDrive/CAF-GAN/mimic-cxr-jpg-2.0.0/files/\",\n",
        "\n",
        "    # --- Synthetic Data Generation ---\n",
        "    \"SYNTHETIC_DATA_DIR\": \"/content/drive/MyDrive/CAF-GAN/data/synthetic_images_final/\",\n",
        "    \"SYNTHETIC_CSV_PATH\": \"/content/drive/MyDrive/CAF-GAN/data/synthetic_images_final/labels.csv\",\n",
        "    \"NUM_SYNTHETIC_IMAGES\": 5000,  # Generate a robust dataset\n",
        "    \"GENERATION_BATCH_SIZE\": 16,     # Smaller batch for 512x512 generation\n",
        "\n",
        "    # --- Downstream Classifier Training (TS-TR) ---\n",
        "    \"CLASSIFIER_OUTPUT_DIR\": \"/content/drive/MyDrive/CAF-GAN/outputs/downstream_classifier_final/\",\n",
        "    \"CLASSIFIER_MODEL_NAME\": \"best_synth_trained_classifier.pth\",\n",
        "    \"CLASSIFIER_IMG_SIZE\": 256,    # ResNet prefers 224 or 256\n",
        "    \"CLASSIFIER_BATCH_SIZE\": 32,\n",
        "    \"CLASSIFIER_EPOCHS\": 15,\n",
        "    \"CLASSIFIER_LR\": 0.0001,\n",
        "\n",
        "    # --- Generator Architecture (MUST MATCH TRAINING) ---\n",
        "    \"TARGET_IMG_SIZE\": 512,\n",
        "    \"LATENT_DIM\": 512,\n",
        "    \"CHANNELS\": 3,\n",
        "    \"BASE_CHANNELS\": 512,\n",
        "\n",
        "    # --- Clinical Plausibility (MUST MATCH TRAINING) ---\n",
        "    # !!! IMPORTANT: Fill these with the values you calculated !!!\n",
        "    \"PLAUSIBLE_LUNG_AREA_MEAN\": 0.220646, # <--- PUT YOUR CALCULATED MEAN HERE\n",
        "    \"PLAUSIBLE_LUNG_AREA_STD\": 0.066277,   # <--- PUT YOUR CALCULATED STD HERE\n",
        "\n",
        "    # --- System ---\n",
        "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"NUM_WORKERS\": 2\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG['SYNTHETIC_DATA_DIR'], exist_ok=True)\n",
        "os.makedirs(CONFIG['CLASSIFIER_OUTPUT_DIR'], exist_ok=True)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# ARCHITECTURE: PROGRESSIVE CAF-GAN (Must match training script)\n",
        "# -------------------------------------------------------------------\n",
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self): super().__init__(); self.epsilon = 1e-8\n",
        "    def forward(self, x):\n",
        "        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
        "\n",
        "class WSConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.scale = (2 / (in_channels * (kernel_size ** 2))) ** 0.5\n",
        "        self.bias = self.conv.bias; self.conv.bias = None\n",
        "        nn.init.normal_(self.conv.weight);\n",
        "        if self.bias is not None: nn.init.zeros_(self.bias)\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x * self.scale)\n",
        "        if self.bias is not None: out = out + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
        "        return out\n",
        "\n",
        "class InjectNoise(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__(); self.weight = nn.Parameter(torch.zeros(1, channels, 1, 1))\n",
        "    def forward(self, x):\n",
        "        noise = torch.randn((x.shape[0], 1, x.shape[2], x.shape[3]), device=x.device)\n",
        "        return x + self.weight * noise\n",
        "\n",
        "class AdaIN(nn.Module):\n",
        "    def __init__(self, channels, w_dim):\n",
        "        super().__init__()\n",
        "        self.instance_norm = nn.InstanceNorm2d(channels)\n",
        "        self.style_scale = nn.Linear(w_dim, channels)\n",
        "        self.style_bias = nn.Linear(w_dim, channels)\n",
        "    def forward(self, x, w):\n",
        "        x = self.instance_norm(x)\n",
        "        style_scale = self.style_scale(w).unsqueeze(2).unsqueeze(3)\n",
        "        style_bias = self.style_bias(w).unsqueeze(2).unsqueeze(3)\n",
        "        return style_scale * x + style_bias\n",
        "\n",
        "class MappingNetwork(nn.Module):\n",
        "    def __init__(self, z_dim, w_dim):\n",
        "        super().__init__()\n",
        "        layers = [PixelNorm()]\n",
        "        for i in range(8):\n",
        "            layers.append(nn.Linear(z_dim if i == 0 else w_dim, w_dim))\n",
        "            if i < 7: layers.append(nn.ReLU())\n",
        "        self.mapping = nn.Sequential(*layers)\n",
        "    def forward(self, x): return self.mapping(x)\n",
        "\n",
        "class GenBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, w_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = WSConv2d(in_channels, out_channels); self.conv2 = WSConv2d(out_channels, out_channels)\n",
        "        self.leaky = nn.LeakyReLU(0.2, inplace=True); self.inject_noise1 = InjectNoise(out_channels)\n",
        "        self.inject_noise2 = InjectNoise(out_channels); self.adain1 = AdaIN(out_channels, w_dim)\n",
        "        self.adain2 = AdaIN(out_channels, w_dim)\n",
        "    def forward(self, x, w):\n",
        "        x = self.leaky(self.inject_noise1(self.conv1(x))); x = self.adain1(x, w)\n",
        "        x = self.leaky(self.inject_noise2(self.conv2(x))); x = self.adain2(x, w)\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, w_dim, base_channels, img_channels=3):\n",
        "        super().__init__()\n",
        "        self.starting_const = nn.Parameter(torch.randn(1, base_channels, 4, 4))\n",
        "        self.map = MappingNetwork(z_dim, w_dim)\n",
        "        self.initial_conv = WSConv2d(base_channels, base_channels, kernel_size=3, padding=1)\n",
        "        self.leaky = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.factors = [512, 512, 512, 256, 128, 64, 32, 16]\n",
        "        self.prog_blocks = nn.ModuleList(); self.to_rgbs = nn.ModuleList()\n",
        "        self.to_rgbs.append(WSConv2d(self.factors[0], img_channels, kernel_size=1, padding=0))\n",
        "        for i in range(1, len(self.factors)):\n",
        "            in_c = self.factors[i-1]; out_c = self.factors[i]\n",
        "            self.prog_blocks.append(GenBlock(in_c, out_c, w_dim))\n",
        "            self.to_rgbs.append(WSConv2d(out_c, img_channels, kernel_size=1, padding=0))\n",
        "\n",
        "    def forward(self, z, alpha, steps):\n",
        "        w = self.map(z); batch = z.shape[0]\n",
        "        x = self.starting_const.repeat(batch, 1, 1, 1); x = self.initial_conv(x); x = self.leaky(x)\n",
        "        if steps == 0: return torch.tanh(self.to_rgbs[0](x))\n",
        "        prev = None\n",
        "        for step in range(1, steps + 1):\n",
        "            prev = x; x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "            x = self.prog_blocks[step - 1](x, w)\n",
        "        final_out = self.to_rgbs[steps](x)\n",
        "        if alpha < 1.0 and prev is not None:\n",
        "            prev_rgb = self.to_rgbs[steps - 1](prev)\n",
        "            prev_rgb_upsampled = F.interpolate(prev_rgb, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "            out = alpha * final_out + (1.0 - alpha) * prev_rgb_upsampled\n",
        "        else: out = final_out\n",
        "        return torch.tanh(out)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DATASET DEFINITIONS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "# Dataset for the *synthetic* images\n",
        "class SyntheticDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = os.path.join(self.image_dir, row['image_id'])\n",
        "        # Load as RGB for ResNet\n",
        "        image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "        label = torch.tensor(row['Pneumonia'], dtype=torch.float32)\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        return image, label.unsqueeze(0)\n",
        "\n",
        "# Dataset for the *real* test images\n",
        "class RealTestDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        subject_id = str(row['subject_id']); study_id = str(row['study_id']); dicom_id = row['dicom_id']\n",
        "        image_path = os.path.join(self.image_dir, f'p{subject_id[:2]}', f'p{subject_id}', f's{study_id}', f'{dicom_id}.jpg')\n",
        "        # Load as RGB for ResNet\n",
        "        image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        label = torch.tensor(row['Pneumonia'], dtype=torch.float32)\n",
        "        race = row['race_group']\n",
        "        return image, label.unsqueeze(0), race\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# HELPER FUNCTION (from training script)\n",
        "# -------------------------------------------------------------------\n",
        "def calculate_clinical_loss_score(fake_masks, config):\n",
        "    \"\"\"Calculates the L_clinical (L_area) score for a batch of masks.\"\"\"\n",
        "    fake_masks_prob = torch.sigmoid(fake_masks)\n",
        "    total_pixels = fake_masks_prob.shape[2] * fake_masks_prob.shape[3]\n",
        "    mask_area_percent = fake_masks_prob.sum(dim=[1, 2, 3]) / total_pixels\n",
        "\n",
        "    mean_area = config[\"PLAUSIBLE_LUNG_AREA_MEAN\"]\n",
        "    std_area = config[\"PLAUSIBLE_LUNG_AREA_STD\"]\n",
        "\n",
        "    # Calculate L1 distance from the mean, normalized by std\n",
        "    area_loss_scores = F.l1_loss(mask_area_percent, torch.tensor(mean_area, device=mask_area_percent.device), reduction='none') / std_area\n",
        "    return area_loss_scores # (B,)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# EVALUATION STEP 1: GENERATE SYNTHETIC DATA\n",
        "# -------------------------------------------------------------------\n",
        "def generate_synthetic_data(config, device):\n",
        "    print(\"--- 1. Generating Synthetic Dataset ---\")\n",
        "\n",
        "    # Load Generator\n",
        "    netG = Generator(\n",
        "        CONFIG['LATENT_DIM'],\n",
        "        CONFIG['LATENT_DIM'],\n",
        "        CONFIG['BASE_CHANNELS'],\n",
        "        CONFIG['CHANNELS']\n",
        "    ).to(device)\n",
        "\n",
        "    # Load the *full* generator state_dict\n",
        "    netG.load_state_dict(torch.load(config['GENERATOR_CHECKPOINT'], map_location=device))\n",
        "    netG.eval()\n",
        "    print(f\"‚úÖ Generator loaded from {config['GENERATOR_CHECKPOINT']}\")\n",
        "\n",
        "    # Create balanced labels for the synthetic data (for robust downstream training)\n",
        "    num_positive = config['NUM_SYNTHETIC_IMAGES'] // 2\n",
        "    labels = np.array([1] * num_positive + [0] * (config['NUM_SYNTHETIC_IMAGES'] - num_positive))\n",
        "    np.random.shuffle(labels)\n",
        "\n",
        "    image_ids = []; generated_labels = []\n",
        "\n",
        "    # This transform resizes the generated 512x512 to 256x256 for the *classifier*\n",
        "    resize_transform = A.Compose([\n",
        "        A.Resize(config['CLASSIFIER_IMG_SIZE'], config['CLASSIFIER_IMG_SIZE'], interpolation=Image.LANCZOS)\n",
        "    ])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, config['NUM_SYNTHETIC_IMAGES'], config['GENERATION_BATCH_SIZE']), desc=\"Generating Images\"):\n",
        "            batch_size = min(config['GENERATION_BATCH_SIZE'], config['NUM_SYNTHETIC_IMAGES'] - i)\n",
        "\n",
        "            # Noise vector for progressive GAN is (B, Z_DIM)\n",
        "            noise = torch.randn(batch_size, config['LATENT_DIM'], device=device)\n",
        "\n",
        "            # Generate at full 512x512 resolution (steps=7, alpha=1.0)\n",
        "            fake_imgs_512 = netG(noise, alpha=1.0, steps=7)\n",
        "\n",
        "            for j in range(batch_size):\n",
        "                img_idx = i + j\n",
        "                image_id = f\"synth_{img_idx:05d}.jpg\"\n",
        "\n",
        "                # Convert tensor to CPU, range [0, 1], then to numpy [0, 255]\n",
        "                img_512_np = fake_imgs_512[j].mul(0.5).add(0.5).clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "                img_512_np = (img_512_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Resize to 256x256 using Albumentations/PIL\n",
        "                img_256_np = resize_transform(image=img_512_np)['image']\n",
        "\n",
        "                # Save the 256x256 image\n",
        "                Image.fromarray(img_256_np).save(os.path.join(config['SYNTHETIC_DATA_DIR'], image_id))\n",
        "\n",
        "                image_ids.append(image_id)\n",
        "                generated_labels.append(labels[img_idx])\n",
        "\n",
        "    synthetic_df = pd.DataFrame({'image_id': image_ids, 'Pneumonia': generated_labels})\n",
        "    synthetic_df.to_csv(config['SYNTHETIC_CSV_PATH'], index=False)\n",
        "    print(f\"‚úÖ Generated {config['NUM_SYNTHETIC_IMAGES']} images, resized to {config['CLASSIFIER_IMG_SIZE']}x{config['CLASSIFIER_IMG_SIZE']}, and saved labels.\")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# EVALUATION STEP 2: TRAIN DOWNSTREAM CLASSIFIER (TS)\n",
        "# -------------------------------------------------------------------\n",
        "def train_downstream_classifier(config, device):\n",
        "    print(\"\\n--- 2. Training Downstream Classifier on Synthetic Data ---\")\n",
        "\n",
        "    transform = A.Compose([\n",
        "        # Synthetic data is already 256x256\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    synth_df = pd.read_csv(config['SYNTHETIC_CSV_PATH'])\n",
        "    train_dataset = SyntheticDataset(synth_df, config['SYNTHETIC_DATA_DIR'], transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['CLASSIFIER_BATCH_SIZE'], shuffle=True, num_workers=config['NUM_WORKERS'])\n",
        "\n",
        "    model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "    model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['CLASSIFIER_LR'])\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(config['CLASSIFIER_EPOCHS']):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['CLASSIFIER_EPOCHS']}\")\n",
        "        for images, labels in loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        if avg_loss < best_loss:\n",
        "             best_loss = avg_loss\n",
        "             torch.save(model.state_dict(), os.path.join(config['CLASSIFIER_OUTPUT_DIR'], config['CLASSIFIER_MODEL_NAME']))\n",
        "             print(f\"   ‚ú® Saved new best model with loss: {avg_loss:.4f}\")\n",
        "\n",
        "    print(\"‚úÖ Downstream classifier training complete.\")\n",
        "    # Load the best model for evaluation\n",
        "    model.load_state_dict(torch.load(os.path.join(config['CLASSIFIER_OUTPUT_DIR'], config['CLASSIFIER_MODEL_NAME'])))\n",
        "    return model\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# EVALUATION STEP 3: TEST ON REAL DATA (TR) - (Utility & Fairness)\n",
        "# -------------------------------------------------------------------\n",
        "def evaluate_on_real_data(classifier, config, device):\n",
        "    print(\"\\n--- 3. Evaluating on Real Test Data (Utility & Fairness) ---\")\n",
        "\n",
        "    transform = A.Compose([\n",
        "        A.Resize(config['CLASSIFIER_IMG_SIZE'], config['CLASSIFIER_IMG_SIZE']),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    test_df = pd.read_csv(config['REAL_DATA_CSV_TEST'])\n",
        "    test_dataset = RealTestDataset(test_df, config['IMAGE_DIR_REAL'], transform=transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config['CLASSIFIER_BATCH_SIZE'], shuffle=False, num_workers=config['NUM_WORKERS'])\n",
        "\n",
        "    classifier.eval()\n",
        "    all_preds, all_labels, all_races = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, races in tqdm(test_loader, desc=\"Evaluating on Real Data\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = classifier(images)\n",
        "            preds = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy().flatten())\n",
        "            all_races.extend(races)\n",
        "\n",
        "    df_results = pd.DataFrame({'label': all_labels, 'pred_prob': all_preds, 'race': all_races})\n",
        "    df_results['prediction'] = (df_results['pred_prob'] > 0.5).astype(int)\n",
        "\n",
        "    # --- üéØ Objective 1: Report on UTILITY ---\n",
        "    auc = roc_auc_score(df_results['label'], df_results['pred_prob'])\n",
        "    accuracy = accuracy_score(df_results['label'], df_results['prediction'])\n",
        "    f1 = f1_score(df_results['label'], df_results['prediction'])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìä EVALUATION REPORT (TS-TR)\")\n",
        "    print(f\"Trained on {config['NUM_SYNTHETIC_IMAGES']} synthetic images. Evaluated on {len(df_results)} real test images.\")\n",
        "    print(\"\\nüéØ Objective 1: Downstream Utility\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "    # --- ‚öñÔ∏è Objective 2: Report on FAIRNESS ---\n",
        "    tpr_per_group = {}\n",
        "    positive_cases = df_results[df_results['label'] == 1]\n",
        "\n",
        "    print(\"\\n‚öñÔ∏è Objective 2: Fairness (Equal Opportunity)\")\n",
        "    print(\"True Positive Rate (TPR) by Group:\")\n",
        "    for group in sorted(positive_cases['race'].unique()):\n",
        "        group_df = positive_cases[positive_cases['race'] == group]\n",
        "        if len(group_df) == 0:\n",
        "            print(f\"  - {group}: N/A (0 positive samples)\")\n",
        "            continue\n",
        "\n",
        "        # Calculate TPR\n",
        "        tp = group_df['prediction'].sum()\n",
        "        total_positives = len(group_df)\n",
        "        tpr = tp / total_positives\n",
        "        tpr_per_group[group] = tpr\n",
        "        print(f\"  - {group}: {tpr:.4f}  (TP: {tp} / Total: {total_positives})\")\n",
        "\n",
        "    if tpr_per_group:\n",
        "        eod = max(tpr_per_group.values()) - min(tpr_per_group.values())\n",
        "        print(f\"\\nEqual Opportunity Difference (Max TPR - Min TPR): {eod:.4f}\")\n",
        "    else:\n",
        "        print(\"\\n**Could not calculate Equal Opportunity Difference.**\")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# EVALUATION STEP 4: EVALUATE CLINICAL PLAUSIBILITY\n",
        "# -------------------------------------------------------------------\n",
        "def evaluate_clinical_plausibility(config, device):\n",
        "    print(\"\\n--- 4. Evaluating Clinical Plausibility (L_area) ---\")\n",
        "\n",
        "    # 1. Load Generator\n",
        "    netG = Generator(\n",
        "        CONFIG['LATENT_DIM'],\n",
        "        CONFIG['LATENT_DIM'],\n",
        "        CONFIG['BASE_CHANNELS'],\n",
        "        CONFIG['CHANNELS']\n",
        "    ).to(device)\n",
        "    netG.load_state_dict(torch.load(config['GENERATOR_CHECKPOINT'], map_location=device))\n",
        "    netG.eval()\n",
        "    print(f\"‚úÖ Generator loaded from {config['GENERATOR_CHECKPOINT']}\")\n",
        "\n",
        "    # 2. Load Cseg\n",
        "    Cseg = smp.Unet(\"resnet34\", in_channels=3, classes=1).to(device)\n",
        "    Cseg.load_state_dict(torch.load(config['CSEG_CHECKPOINT'], map_location=device))\n",
        "    Cseg.eval()\n",
        "    print(f\"‚úÖ Cseg loaded from {config['CSEG_CHECKPOINT']}\")\n",
        "\n",
        "    num_eval_images = 1000 # Evaluate on a large sample\n",
        "    all_clinical_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, num_eval_images, config['GENERATION_BATCH_SIZE']), desc=\"Evaluating Plausibility\"):\n",
        "            batch_size = min(config['GENERATION_BATCH_SIZE'], num_eval_images - i)\n",
        "            noise = torch.randn(batch_size, config['LATENT_DIM'], device=device)\n",
        "\n",
        "            # Generate at full 512x512\n",
        "            fake_imgs_512 = netG(noise, alpha=1.0, steps=7)\n",
        "\n",
        "            # Get segmentation masks from Cseg\n",
        "            fake_masks = Cseg(fake_imgs_512)\n",
        "\n",
        "            # Get the plausibility score (L_area) for each image\n",
        "            scores = calculate_clinical_loss_score(fake_masks, config)\n",
        "            all_clinical_scores.append(scores.cpu())\n",
        "\n",
        "    all_clinical_scores = torch.cat(all_clinical_scores)\n",
        "    mean_score = torch.mean(all_clinical_scores).item()\n",
        "    std_score = torch.std(all_clinical_scores).item()\n",
        "\n",
        "    print(\"\\n## ü©∫ Objective 3: Clinical Plausibility (L_area Score)\")\n",
        "    print(f\"Evaluated on {num_eval_images} synthetic images.\")\n",
        "    print(f\"Mean L_area Score: {mean_score:.4f}\")\n",
        "    print(f\"Std Dev L_area Score: {std_score:.4f}\")\n",
        "    # print(f\"(A lower mean score is better, indicating generated masks are close to the plausible mean area)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MAIN EXECUTION\n",
        "# -------------------------------------------------------------------\n",
        "def main(config):\n",
        "    device = config['DEVICE']\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --- Objective 1 & 2: Utility and Fairness ---\n",
        "    # 1. Generate synthetic data\n",
        "    generate_synthetic_data(config, device)\n",
        "\n",
        "    # 2. Train classifier on synthetic data\n",
        "    trained_classifier = train_downstream_classifier(config, device)\n",
        "\n",
        "    # 3. Evaluate classifier on real data\n",
        "    evaluate_on_real_data(trained_classifier, config, device)\n",
        "\n",
        "    # --- Objective 3: Clinical Plausibility ---\n",
        "    # 4. Evaluate generated images using Cseg\n",
        "    evaluate_clinical_plausibility(config, device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Mount drive first\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Set your project directory\n",
        "    %cd /content/drive/MyDrive/CAF-GAN/\n",
        "\n",
        "    # Run the full evaluation\n",
        "    main(CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aXdMkHRsjcE",
        "outputId": "faf190cb-4734-469d-a6f0-3b6f3c7c10c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CAF-GAN\n",
            "Using device: cuda\n",
            "--- 1. Generating Synthetic Dataset ---\n",
            "‚úÖ Generator loaded from /content/drive/MyDrive/CAF-GAN/outputs/caf_gan_final/caf_gan_generator_final.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [32:10<00:00,  6.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Generated 5000 images, resized to 256x256, and saved labels.\n",
            "\n",
            "--- 2. Training Downstream Classifier on Synthetic Data ---\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 190MB/s]\n",
            "Epoch 1/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:59<00:00,  2.62it/s, loss=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.7063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.56it/s, loss=0.647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.6964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.57it/s, loss=0.698]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.6874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:02<00:00,  2.51it/s, loss=0.618]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.6752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.56it/s, loss=0.661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.6481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.55it/s, loss=0.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.5895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.56it/s, loss=0.361]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.4864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.54it/s, loss=0.734]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.3838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.55it/s, loss=0.544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.2645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.55it/s, loss=0.0234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.2122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.55it/s, loss=0.0486]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.1672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.54it/s, loss=0.0173]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.1259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.55it/s, loss=0.183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.0976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [01:01<00:00,  2.54it/s, loss=2.16]\n",
            "Epoch 15/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:59<00:00,  2.62it/s, loss=0.00684]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ú® Saved new best model with loss: 0.0963\n",
            "‚úÖ Downstream classifier training complete.\n",
            "\n",
            "--- 3. Evaluating on Real Test Data (Utility & Fairness) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating on Real Data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:38<00:00,  9.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üìä EVALUATION REPORT (TS-TR)\n",
            "Trained on 5000 synthetic images. Evaluated on 301 real test images.\n",
            "\n",
            "üéØ Objective 1: Downstream Utility\n",
            "AUC: 0.5149\n",
            "Accuracy: 0.3953\n",
            "F1-Score: 0.5260\n",
            "\n",
            "‚öñÔ∏è Objective 2: Fairness (Equal Opportunity)\n",
            "True Positive Rate (TPR) by Group:\n",
            "  - ASIAN: 1.0000  (TP: 4 / Total: 4)\n",
            "  - BLACK: 0.8333  (TP: 15 / Total: 18)\n",
            "  - HISPANIC/LATINO: 0.8333  (TP: 5 / Total: 6)\n",
            "  - OTHER: 0.7500  (TP: 6 / Total: 8)\n",
            "  - WHITE: 0.8987  (TP: 71 / Total: 79)\n",
            "\n",
            "Equal Opportunity Difference (Max TPR - Min TPR): 0.2500\n",
            "\n",
            "--- 4. Evaluating Clinical Plausibility (L_area) ---\n",
            "‚úÖ Generator loaded from /content/drive/MyDrive/CAF-GAN/outputs/caf_gan_final/caf_gan_generator_final.pth\n",
            "‚úÖ Cseg loaded from /content/drive/MyDrive/CAF-GAN/outputs/cseg_512/best_cseg_512.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Plausibility: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:23<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## ü©∫ Objective 3: Clinical Plausibility (L_area Score)\n",
            "Evaluated on 1000 synthetic images.\n",
            "Mean L_area Score: 0.3856\n",
            "Std Dev L_area Score: 0.2974\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}