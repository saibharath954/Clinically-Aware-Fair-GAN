{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrhYk2bxB_Yx",
        "outputId": "f024dbad-3673-4d7c-c56d-b64bfcef9f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8VZ0P_1C4Kq",
        "outputId": "6c88caa3-1014-45e1-e2ee-ee69ca7ec022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml pandas scikit-learn albumentations segmentation-models-pytorch -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0dykhuKZtMp",
        "outputId": "550c2793-b3bf-4bfd-84ed-19e78776db5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting high-resolution mask generation...\n",
            "Using device: cuda\n",
            "ğŸ’¾ Loading trained weights from: /content/drive/MyDrive/CAF-GAN/lung_segmentation_data/outputs/best_lung_segmenter.pth\n",
            "ğŸ–¼ï¸ Found 2000 images to process.\n",
            "ğŸ’¾ Masks will be saved to /content/drive/MyDrive/CAF-GAN/data/masks_512x512/ at 512x512 resolution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Masks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [27:54<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Mask generation complete!\n",
            "ğŸ“ˆ Success: 2000, Failed: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from scipy import ndimage\n",
        "\n",
        "# --- âš™ï¸ Configuration ---\n",
        "CSV_PATH = '/content/drive/MyDrive/CAF-GAN/data/splits/master_subset_2k.csv' # Or your full dataset CSV\n",
        "IMAGE_DIR = '/content/drive/MyDrive/CAF-GAN/mimic-cxr-jpg-2.0.0/files/'\n",
        "MASK_DIR = '/content/drive/MyDrive/CAF-GAN/data/masks_512x512/' # New directory for high-res masks\n",
        "MODEL_WEIGHTS_PATH = '/content/drive/MyDrive/CAF-GAN/lung_segmentation_data/outputs/best_lung_segmenter.pth' # <--- PATH TO YOUR TRAINED MODEL WEIGHTS\n",
        "IMG_SIZE = 512\n",
        "\n",
        "def preprocess_image(image_path, transform):\n",
        "    \"\"\"Loads and preprocesses a single image for inference.\"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    if transform:\n",
        "        augmented = transform(image=image_np)\n",
        "        image_tensor = augmented['image']\n",
        "\n",
        "    return image_tensor.unsqueeze(0)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Generates high-resolution segmentation masks using a pre-trained model.\"\"\"\n",
        "    print(\"ğŸš€ Starting high-resolution mask generation...\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --- Model Definition ---\n",
        "    # This model should be identical to the one you trained for lung segmentation.\n",
        "    model = smp.Unet(\n",
        "        encoder_name=\"resnet34\",\n",
        "        encoder_weights=None,  # Weights will be loaded from your trained file\n",
        "        in_channels=3,\n",
        "        classes=1,\n",
        "    )\n",
        "\n",
        "    # --- Load Your Trained Weights ---\n",
        "    # This is the most important step!\n",
        "    print(f\"ğŸ’¾ Loading trained weights from: {MODEL_WEIGHTS_PATH}\")\n",
        "    # Ensure the model is loaded correctly for the device\n",
        "    model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # --- Transformation Pipeline for Inference ---\n",
        "    # This should only include resizing and normalization, not augmentations like flips/rotations.\n",
        "    transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=Image.LANCZOS),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    # --- Data Handling ---\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    os.makedirs(MASK_DIR, exist_ok=True)\n",
        "    print(f\"ğŸ–¼ï¸ Found {len(df)} images to process.\")\n",
        "    print(f\"ğŸ’¾ Masks will be saved to {MASK_DIR} at {IMG_SIZE}x{IMG_SIZE} resolution.\")\n",
        "\n",
        "    successful_generations = 0\n",
        "    failed_generations = 0\n",
        "\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating Masks\"):\n",
        "        subject_id = str(row['subject_id'])\n",
        "        study_id = str(row['study_id'])\n",
        "        dicom_id = row['dicom_id']\n",
        "\n",
        "        jpg_path = os.path.join(\n",
        "            IMAGE_DIR, f'p{subject_id[:2]}', f'p{subject_id}', f's{study_id}', f'{dicom_id}.jpg'\n",
        "        )\n",
        "\n",
        "        if not os.path.exists(jpg_path):\n",
        "            failed_generations += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            image_tensor = preprocess_image(jpg_path, transform).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                predicted_mask = model(image_tensor)\n",
        "\n",
        "            # --- Post-processing for a clean mask ---\n",
        "            probabilities = torch.sigmoid(predicted_mask).squeeze().cpu().numpy()\n",
        "            binary_mask = (probabilities > 0.5).astype(np.uint8)\n",
        "\n",
        "            # Morphological operations to remove small artifacts and fill holes\n",
        "            binary_mask = ndimage.binary_closing(binary_mask, structure=np.ones((5,5))).astype(np.uint8)\n",
        "            binary_mask = ndimage.binary_opening(binary_mask, structure=np.ones((3,3))).astype(np.uint8)\n",
        "\n",
        "            # Convert back to an image format for saving\n",
        "            mask_to_save = (binary_mask * 255)\n",
        "            mask_image = Image.fromarray(mask_to_save)\n",
        "\n",
        "            output_path = os.path.join(MASK_DIR, f\"{dicom_id}.png\")\n",
        "            mask_image.save(output_path)\n",
        "            successful_generations += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {jpg_path}: {e}\")\n",
        "            failed_generations += 1\n",
        "\n",
        "    print(\"\\nâœ… Mask generation complete!\")\n",
        "    print(f\"ğŸ“ˆ Success: {successful_generations}, Failed: {failed_generations}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}