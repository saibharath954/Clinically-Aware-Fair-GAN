{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-SLNowBkuUo",
        "outputId": "b1a3780b-b3fa-4874-b455-fe777a1f2553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA5jjLFak30s",
        "outputId": "4576e4ae-0212-4d4e-ba41-035c7ff7bcc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml pandas scikit-learn joblib albumentations segmentation-models-pytorch -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFtv58-Lk6Jl",
        "outputId": "8ee520cc-1277-450a-eddc-9fa66efb90f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ],
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gKgtcymk9Pf"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mTcXE-gk_FM",
        "outputId": "aed42697-3b2a-4c75-9770-39cad8e73572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Generator loaded.\n",
            "‚úÖ Cdiag loaded.\n",
            "‚úÖ Existing balanced synthetic dataset found (2500,2500). Loading features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading synthetic features:   0%|          | 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Loading synthetic features:   1%|‚ñè         | 1/79 [00:00<01:06,  1.17it/s]\u001b[A\n",
            "Loading synthetic features:   3%|‚ñé         | 2/79 [00:01<01:04,  1.20it/s]\u001b[A\n",
            "Loading synthetic features:   4%|‚ñç         | 3/79 [00:02<01:03,  1.20it/s]\u001b[A\n",
            "Loading synthetic features:   5%|‚ñå         | 4/79 [00:03<01:03,  1.18it/s]\u001b[A\n",
            "Loading synthetic features:   6%|‚ñã         | 5/79 [00:04<00:58,  1.26it/s]\u001b[A\n",
            "Loading synthetic features:   8%|‚ñä         | 6/79 [00:04<00:57,  1.27it/s]\u001b[A\n",
            "Loading synthetic features:   9%|‚ñâ         | 7/79 [00:05<00:54,  1.31it/s]\u001b[A\n",
            "Loading synthetic features:  10%|‚ñà         | 8/79 [00:06<00:53,  1.33it/s]\u001b[A\n",
            "Loading synthetic features:  11%|‚ñà‚ñè        | 9/79 [00:07<00:52,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  13%|‚ñà‚ñé        | 10/79 [00:07<00:50,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  14%|‚ñà‚ñç        | 11/79 [00:08<00:49,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  15%|‚ñà‚ñå        | 12/79 [00:09<00:49,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  16%|‚ñà‚ñã        | 13/79 [00:09<00:47,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  18%|‚ñà‚ñä        | 14/79 [00:10<00:47,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  19%|‚ñà‚ñâ        | 15/79 [00:11<00:46,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  20%|‚ñà‚ñà        | 16/79 [00:12<00:45,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  22%|‚ñà‚ñà‚ñè       | 17/79 [00:12<00:44,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  23%|‚ñà‚ñà‚ñé       | 18/79 [00:13<00:43,  1.39it/s]\u001b[A\n",
            "Loading synthetic features:  24%|‚ñà‚ñà‚ñç       | 19/79 [00:14<00:45,  1.33it/s]\u001b[A\n",
            "Loading synthetic features:  25%|‚ñà‚ñà‚ñå       | 20/79 [00:15<00:46,  1.27it/s]\u001b[A\n",
            "Loading synthetic features:  27%|‚ñà‚ñà‚ñã       | 21/79 [00:16<00:46,  1.24it/s]\u001b[A\n",
            "Loading synthetic features:  28%|‚ñà‚ñà‚ñä       | 22/79 [00:16<00:47,  1.21it/s]\u001b[A\n",
            "Loading synthetic features:  29%|‚ñà‚ñà‚ñâ       | 23/79 [00:17<00:44,  1.26it/s]\u001b[A\n",
            "Loading synthetic features:  30%|‚ñà‚ñà‚ñà       | 24/79 [00:18<00:42,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  32%|‚ñà‚ñà‚ñà‚ñè      | 25/79 [00:19<00:40,  1.33it/s]\u001b[A\n",
            "Loading synthetic features:  33%|‚ñà‚ñà‚ñà‚ñé      | 26/79 [00:19<00:39,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  34%|‚ñà‚ñà‚ñà‚ñç      | 27/79 [00:20<00:38,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  35%|‚ñà‚ñà‚ñà‚ñå      | 28/79 [00:21<00:37,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  37%|‚ñà‚ñà‚ñà‚ñã      | 29/79 [00:21<00:36,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  38%|‚ñà‚ñà‚ñà‚ñä      | 30/79 [00:22<00:35,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:23<00:35,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  41%|‚ñà‚ñà‚ñà‚ñà      | 32/79 [00:24<00:33,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 33/79 [00:24<00:33,  1.39it/s]\u001b[A\n",
            "Loading synthetic features:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 34/79 [00:25<00:32,  1.40it/s]\u001b[A\n",
            "Loading synthetic features:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 35/79 [00:26<00:31,  1.40it/s]\u001b[A\n",
            "Loading synthetic features:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 36/79 [00:27<00:31,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 37/79 [00:27<00:32,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 38/79 [00:28<00:32,  1.27it/s]\u001b[A\n",
            "Loading synthetic features:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 39/79 [00:29<00:32,  1.23it/s]\u001b[A\n",
            "Loading synthetic features:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 40/79 [00:30<00:30,  1.27it/s]\u001b[A\n",
            "Loading synthetic features:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 41/79 [00:31<00:29,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 42/79 [00:31<00:27,  1.32it/s]\u001b[A\n",
            "Loading synthetic features:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 43/79 [00:32<00:26,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 44/79 [00:33<00:25,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 45/79 [00:33<00:24,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 46/79 [00:34<00:23,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 47/79 [00:35<00:23,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 48/79 [00:36<00:22,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 49/79 [00:36<00:21,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 50/79 [00:37<00:20,  1.39it/s]\u001b[A\n",
            "Loading synthetic features:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 51/79 [00:38<00:20,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 52/79 [00:39<00:19,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 53/79 [00:39<00:19,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 54/79 [00:40<00:19,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 55/79 [00:41<00:19,  1.26it/s]\u001b[A\n",
            "Loading synthetic features:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 56/79 [00:42<00:18,  1.23it/s]\u001b[A\n",
            "Loading synthetic features:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/79 [00:43<00:17,  1.23it/s]\u001b[A\n",
            "Loading synthetic features:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:43<00:16,  1.27it/s]\u001b[A\n",
            "Loading synthetic features:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:44<00:15,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 60/79 [00:45<00:14,  1.32it/s]\u001b[A\n",
            "Loading synthetic features:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/79 [00:46<00:13,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 62/79 [00:46<00:12,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:47<00:11,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:48<00:11,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 65/79 [00:48<00:10,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 66/79 [00:49<00:09,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 67/79 [00:50<00:08,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 68/79 [00:51<00:07,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 69/79 [00:51<00:07,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 70/79 [00:53<00:08,  1.10it/s]\u001b[A\n",
            "Loading synthetic features:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 71/79 [00:55<00:10,  1.29s/it]\u001b[A\n",
            "Loading synthetic features:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 72/79 [00:56<00:08,  1.24s/it]\u001b[A\n",
            "Loading synthetic features:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 73/79 [00:57<00:06,  1.08s/it]\u001b[A\n",
            "Loading synthetic features:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 74/79 [00:57<00:04,  1.02it/s]\u001b[A\n",
            "Loading synthetic features:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 75/79 [00:58<00:03,  1.11it/s]\u001b[A\n",
            "Loading synthetic features:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 76/79 [00:59<00:02,  1.18it/s]\u001b[A\n",
            "Loading synthetic features:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 77/79 [01:00<00:01,  1.23it/s]\u001b[A\n",
            "Loading synthetic features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [01:00<00:00,  1.30it/s]\n",
            "\n",
            "Extracting real features:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Extracting real features:  10%|‚ñà         | 1/10 [00:03<00:29,  3.22s/it]\u001b[A\n",
            "Extracting real features:  20%|‚ñà‚ñà        | 2/10 [00:03<00:11,  1.43s/it]\u001b[A\n",
            "Extracting real features:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:06<00:15,  2.23s/it]\u001b[A\n",
            "Extracting real features:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:06<00:08,  1.41s/it]\u001b[A\n",
            "Extracting real features:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:10<00:11,  2.24s/it]\u001b[A\n",
            "Extracting real features:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:10<00:06,  1.54s/it]\u001b[A\n",
            "Extracting real features:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:13<00:05,  1.95s/it]\u001b[A\n",
            "Extracting real features:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:13<00:02,  1.38s/it]\u001b[A\n",
            "Extracting real features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:15<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Completed evaluation for LogisticRegression.\n",
            "   Completed evaluation for RandomForest.\n",
            "   Completed evaluation for SVM.\n",
            "\n",
            "üìä Results table saved to: /content/drive/MyDrive/CAF-GAN/outputs/evaluation_results_master_v4/tstr_trtr_comparison_v4.csv\n",
            "\n",
            "ü©∫ Calculating Clinical Score (L_area) using Cseg...\n",
            "‚úÖ Cseg loaded.\n",
            "   üëâ Clinical L_area Score: 1.8620\n",
            "\n",
            "‚úÖ MASTER_v4 complete. Outputs saved to: /content/drive/MyDrive/CAF-GAN/outputs/evaluation_results_master_v4/\n",
            "{'results_table':                       Method          Classifier       AUC  Accuracy        F1\n",
            "0              Train on Real  LogisticRegression  0.563776  0.659341  0.474576\n",
            "1  Train on Synthetic (TSTR)  LogisticRegression  0.647959  0.648352  0.238095\n",
            "2              Train on Real        RandomForest  0.560969  0.593407  0.350877\n",
            "3  Train on Synthetic (TSTR)        RandomForest  0.651276  0.626374  0.190476\n",
            "4              Train on Real                 SVM  0.566582  0.670330  0.375000\n",
            "5  Train on Synthetic (TSTR)                 SVM  0.573980  0.659341  0.279070, 'fairness': {'eod': 0.3333333333333333, 'tprs': {'ASIAN': np.float64(0.0), 'BLACK': np.float64(0.0), 'HISPANIC/LATINO': np.float64(0.3333333333333333), 'OTHER': np.float64(0.2), 'WHITE': np.float64(0.09090909090909091)}, 'clinical_L_area': 1.8619920015335083, 'synth_count': 5000}, 'clinical_score': 1.8619920015335083}\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "MASTER_v4 - Paper-ready TSTR + Fairness + Clinical evaluation script\n",
        "- Uses pre-generated balanced synthetic data (option A)\n",
        "- Evaluates LR, RF, SVM for Train-on-Real and Train-on-Synth (TSTR)\n",
        "- Saves .joblib downstream models to CLASSIFIER_OUTPUT_DIR\n",
        "- Saves confusion matrices, results CSVs, and a summary CSV\n",
        "- Robust memory-safe feature extraction + clinical scoring using Cseg\n",
        "- Includes path to user's uploaded file for reproducibility tooling\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "import joblib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Path to the uploaded file (developer instruction)\n",
        "USER_UPLOADED_FILE = \"/mnt/data/b77eaff1-0448-4a1c-b99a-2cc8209bda8c.pdf\"\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG - change if needed\n",
        "# -------------------------\n",
        "CONFIG = {\n",
        "    # Checkpoints\n",
        "    \"GENERATOR_CHECKPOINT\": \"/content/drive/MyDrive/CAF-GAN/outputs/caf_gan_final/caf_gan_generator_final.pth\",\n",
        "    \"CDIAG_CHECKPOINT\": \"/content/drive/MyDrive/CAF-GAN/outputs/cdiag_512/best_cdiag_512.pth\",\n",
        "    \"CSEG_CHECKPOINT\": \"/content/drive/MyDrive/CAF-GAN/outputs/cseg_512/best_cseg_512.pth\",\n",
        "\n",
        "    # Data\n",
        "    \"REAL_TEST_CSV\": \"/content/drive/MyDrive/CAF-GAN/data/splits/test.csv\",\n",
        "    \"REAL_IMAGE_DIR\": \"/content/drive/MyDrive/CAF-GAN/mimic-cxr-jpg-2.0.0/files/\",\n",
        "\n",
        "    # Use existing balanced synthetic (choice A)\n",
        "    \"SYNTHETIC_IMAGE_DIR\": \"/content/drive/MyDrive/CAF-GAN/data/synthetic_images_balanced/\",\n",
        "    \"SYNTHETIC_CSV_PATH\": \"/content/drive/MyDrive/CAF-GAN/data/synthetic_images_balanced/labels.csv\",\n",
        "\n",
        "    # Outputs\n",
        "    \"OUTPUT_DIR\": \"/content/drive/MyDrive/CAF-GAN/outputs/evaluation_results_master_v4/\",\n",
        "    \"CLASSIFIER_OUTPUT_DIR\": \"/content/drive/MyDrive/CAF-GAN/outputs/classifiers/\",\n",
        "\n",
        "    # Model params\n",
        "    \"LATENT_DIM\": 512,\n",
        "    \"BASE_CHANNELS\": 512,\n",
        "    \"CHANNELS\": 3,\n",
        "    \"EVAL_IMG_SIZE\": 224,   # for ResNet feature extractor\n",
        "    \"SEG_IMG_SIZE\": 512,    # for Cseg clinical scoring\n",
        "\n",
        "    # Dataset / runtime\n",
        "    \"TARGET_PER_CLASS\": 2500,\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"NUM_WORKERS\": 2,\n",
        "    \"MANUAL_SEED\": 42,\n",
        "\n",
        "    # Fairness / clinical\n",
        "    \"MIN_GROUP_POSITIVES_FOR_TPR\": 1,  # show TPR for small groups (paper)\n",
        "    \"PLAUSIBLE_LUNG_AREA_MEAN\": 0.220646,\n",
        "    \"PLAUSIBLE_LUNG_AREA_STD\": 0.066277,\n",
        "\n",
        "    # Misc\n",
        "    \"SAVE_DOWNSTREAM_MODELS\": True,\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG['OUTPUT_DIR'], exist_ok=True)\n",
        "os.makedirs(CONFIG['CLASSIFIER_OUTPUT_DIR'], exist_ok=True)\n",
        "os.makedirs(CONFIG['SYNTHETIC_IMAGE_DIR'], exist_ok=True)\n",
        "\n",
        "torch.manual_seed(CONFIG['MANUAL_SEED'])\n",
        "np.random.seed(CONFIG['MANUAL_SEED'])\n",
        "\n",
        "# -------------------------\n",
        "# Generator architecture (same as trained model)\n",
        "# -------------------------\n",
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self): super().__init__(); self.epsilon = 1e-8\n",
        "    def forward(self, x): return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
        "\n",
        "class WSConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.scale = (2 / (in_channels * (kernel_size ** 2))) ** 0.5\n",
        "        self.bias = self.conv.bias; self.conv.bias = None\n",
        "        nn.init.normal_(self.conv.weight)\n",
        "        if self.bias is not None: nn.init.zeros_(self.bias)\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x * self.scale)\n",
        "        if self.bias is not None: out = out + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
        "        return out\n",
        "\n",
        "class InjectNoise(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__(); self.weight = nn.Parameter(torch.zeros(1, channels, 1, 1))\n",
        "    def forward(self, x):\n",
        "        noise = torch.randn((x.shape[0], 1, x.shape[2], x.shape[3]), device=x.device)\n",
        "        return x + self.weight * noise\n",
        "\n",
        "class AdaIN(nn.Module):\n",
        "    def __init__(self, channels, w_dim):\n",
        "        super().__init__()\n",
        "        self.instance_norm = nn.InstanceNorm2d(channels)\n",
        "        self.style_scale = nn.Linear(w_dim, channels)\n",
        "        self.style_bias = nn.Linear(w_dim, channels)\n",
        "    def forward(self, x, w):\n",
        "        x = self.instance_norm(x)\n",
        "        style_scale = self.style_scale(w).unsqueeze(2).unsqueeze(3)\n",
        "        style_bias = self.style_bias(w).unsqueeze(2).unsqueeze(3)\n",
        "        return style_scale * x + style_bias\n",
        "\n",
        "class MappingNetwork(nn.Module):\n",
        "    def __init__(self, z_dim, w_dim):\n",
        "        super().__init__()\n",
        "        layers = [PixelNorm()]\n",
        "        for i in range(8):\n",
        "            layers.append(nn.Linear(z_dim if i == 0 else w_dim, w_dim))\n",
        "            if i < 7: layers.append(nn.ReLU())\n",
        "        self.mapping = nn.Sequential(*layers)\n",
        "    def forward(self, x): return self.mapping(x)\n",
        "\n",
        "class GenBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, w_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = WSConv2d(in_channels, out_channels); self.conv2 = WSConv2d(out_channels, out_channels)\n",
        "        self.leaky = nn.LeakyReLU(0.2, inplace=True); self.inject_noise1 = InjectNoise(out_channels)\n",
        "        self.inject_noise2 = InjectNoise(out_channels); self.adain1 = AdaIN(out_channels, w_dim)\n",
        "        self.adain2 = AdaIN(out_channels, w_dim)\n",
        "    def forward(self, x, w):\n",
        "        x = self.leaky(self.inject_noise1(self.conv1(x))); x = self.adain1(x, w)\n",
        "        x = self.leaky(self.inject_noise2(self.conv2(x))); x = self.adain2(x, w)\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, w_dim, base_channels, img_channels=3):\n",
        "        super().__init__()\n",
        "        self.starting_const = nn.Parameter(torch.randn(1, base_channels, 4, 4))\n",
        "        self.map = MappingNetwork(z_dim, w_dim)\n",
        "        self.initial_conv = WSConv2d(base_channels, base_channels, kernel_size=3, padding=1)\n",
        "        self.leaky = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.factors = [512, 512, 512, 256, 128, 64, 32, 16]\n",
        "        self.prog_blocks = nn.ModuleList(); self.to_rgbs = nn.ModuleList()\n",
        "        self.to_rgbs.append(WSConv2d(self.factors[0], img_channels, kernel_size=1, padding=0))\n",
        "        for i in range(1, len(self.factors)):\n",
        "            in_c = self.factors[i-1]; out_c = self.factors[i]\n",
        "            self.prog_blocks.append(GenBlock(in_c, out_c, w_dim))\n",
        "            self.to_rgbs.append(WSConv2d(out_c, img_channels, kernel_size=1, padding=0))\n",
        "\n",
        "    def forward(self, z, alpha, steps):\n",
        "        w = self.map(z); batch = z.shape[0]\n",
        "        x = self.starting_const.repeat(batch, 1, 1, 1); x = self.initial_conv(x); x = self.leaky(x)\n",
        "        if steps == 0: return torch.tanh(self.to_rgbs[0](x))\n",
        "        prev = None\n",
        "        for step in range(1, steps + 1):\n",
        "            prev = x; x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "            x = self.prog_blocks[step - 1](x, w)\n",
        "        final_out = self.to_rgbs[steps](x)\n",
        "        if alpha < 1.0 and prev is not None:\n",
        "            prev_rgb = self.to_rgbs[steps - 1](prev)\n",
        "            prev_rgb_upsampled = F.interpolate(prev_rgb, scale_factor=2, mode='bilinear', align_corners=False)\n",
        "            out = alpha * final_out + (1.0 - alpha) * prev_rgb_upsampled\n",
        "        else: out = final_out\n",
        "        return torch.tanh(out)\n",
        "\n",
        "# -------------------------\n",
        "# Dataset loader for real data (keeps race)\n",
        "# -------------------------\n",
        "class RobustRealDatasetWithRace(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None, eval_size=CONFIG['EVAL_IMG_SIZE']):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.eval_size = eval_size\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        subject_id = str(row['subject_id']); study_id = str(row['study_id']); dicom_id = row['dicom_id']\n",
        "        image_path = os.path.join(self.image_dir, f'p{subject_id[:2]}', f'p{subject_id}', f's{study_id}', f'{dicom_id}.jpg')\n",
        "        if not os.path.exists(image_path):\n",
        "            return torch.zeros((3, self.eval_size, self.eval_size), dtype=torch.float32), torch.tensor(-1.0), \"Unknown\"\n",
        "        try:\n",
        "            img = Image.open(image_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                arr = np.array(img)\n",
        "                out = self.transform(image=arr)['image']\n",
        "            else:\n",
        "                out = transforms.ToTensor()(img)\n",
        "            label = torch.tensor(row['Pneumonia'], dtype=torch.float32)\n",
        "            race = row.get('race_group', 'Unknown')\n",
        "            return out, label, race\n",
        "        except Exception:\n",
        "            return torch.zeros((3, self.eval_size, self.eval_size), dtype=torch.float32), torch.tensor(-1.0), \"Unknown\"\n",
        "\n",
        "# -------------------------\n",
        "# Preprocessor for ResNet/Cseg\n",
        "# -------------------------\n",
        "class Preprocessor:\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.mean = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1,3,1,1)\n",
        "        self.std = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1,3,1,1)\n",
        "    def gan_to_01(self, x): return (x + 1.0) * 0.5\n",
        "    def prepare_for_resnet(self, x):\n",
        "        if x.dim() == 3: x = x.unsqueeze(0)\n",
        "        x01 = self.gan_to_01(x)\n",
        "        x_resized = F.interpolate(x01, size=(CONFIG['EVAL_IMG_SIZE'], CONFIG['EVAL_IMG_SIZE']), mode='bilinear', align_corners=False)\n",
        "        x_norm = (x_resized - self.mean) / self.std\n",
        "        return x_norm\n",
        "    def prepare_for_cseg(self, x):\n",
        "        # Ensure in [0,1] and size SEG_IMG_SIZE, NO ImageNet normalization (we pass [0,1])\n",
        "        if x.dim() == 3: x = x.unsqueeze(0)\n",
        "        x01 = self.gan_to_01(x) if x.max() <= 1.0 or x.min() < -0.5 else x\n",
        "        x_resized = F.interpolate(x01, size=(CONFIG['SEG_IMG_SIZE'], CONFIG['SEG_IMG_SIZE']), mode='bilinear', align_corners=False)\n",
        "        return x_resized\n",
        "\n",
        "# -------------------------\n",
        "# Plotting helpers\n",
        "# -------------------------\n",
        "def save_confusion_matrix(y_true, y_pred, labels, outpath, title=\"Confusion Matrix\"):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.title(title)\n",
        "    plt.tight_layout(); plt.savefig(outpath); plt.close()\n",
        "\n",
        "# -------------------------\n",
        "# MASTER V4 evaluator\n",
        "# -------------------------\n",
        "class MasterEvaluatorV4:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(config['DEVICE'])\n",
        "        self.preproc = Preprocessor(self.device)\n",
        "\n",
        "        # Load generator\n",
        "        self.generator = Generator(config['LATENT_DIM'], config['LATENT_DIM'], config['BASE_CHANNELS'], config['CHANNELS']).to(self.device)\n",
        "        try:\n",
        "            ckpt = torch.load(config['GENERATOR_CHECKPOINT'], map_location=self.device)\n",
        "            if isinstance(ckpt, dict):\n",
        "                if 'gen' in ckpt: self.generator.load_state_dict(ckpt['gen'])\n",
        "                elif 'state_dict' in ckpt: self.generator.load_state_dict(ckpt['state_dict'])\n",
        "                else: self.generator.load_state_dict(ckpt)\n",
        "            else:\n",
        "                self.generator.load_state_dict(ckpt)\n",
        "            self.generator.eval()\n",
        "            print(\"‚úÖ Generator loaded.\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to load generator: {e}\")\n",
        "\n",
        "        # Load Cdiag (ResNet50)\n",
        "        self.cdiag = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "        self.cdiag.fc = nn.Linear(self.cdiag.fc.in_features, 1)\n",
        "        try:\n",
        "            self.cdiag.load_state_dict(torch.load(config['CDIAG_CHECKPOINT'], map_location=self.device))\n",
        "            print(\"‚úÖ Cdiag loaded.\")\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è Cdiag checkpoint missing/invalid; using ImageNet init.\")\n",
        "        self.cdiag.to(self.device).eval()\n",
        "\n",
        "        # feature extractor (remove final fc)\n",
        "        self.feature_extractor = nn.Sequential(*list(self.cdiag.children())[:-1]).to(self.device).eval()\n",
        "\n",
        "    # Load existing balanced synthetic features from CSV (memory-safe)\n",
        "    def load_synthetic_features_from_disk(self, df):\n",
        "        df = df.reset_index(drop=True)\n",
        "        feats = []\n",
        "        labels = []\n",
        "        # We'll process in small batches to avoid OOM\n",
        "        batch_paths = []\n",
        "        batch_labels = []\n",
        "        for _, row in df.iterrows():\n",
        "            batch_paths.append(os.path.join(self.config['SYNTHETIC_IMAGE_DIR'], str(row['image_id'])))\n",
        "            batch_labels.append(int(row['Pneumonia']))\n",
        "        # process in mini-batches\n",
        "        bs = 64\n",
        "        with torch.no_grad():\n",
        "            for i in tqdm(range(0, len(batch_paths), bs), desc=\"Loading synthetic features\"):\n",
        "                paths_chunk = batch_paths[i:i+bs]\n",
        "                labs_chunk = batch_labels[i:i+bs]\n",
        "                imgs = []\n",
        "                for p in paths_chunk:\n",
        "                    try:\n",
        "                        img = Image.open(p).convert(\"RGB\")\n",
        "                        t = transforms.ToTensor()(img)  # [0,1]\n",
        "                        imgs.append(t)\n",
        "                    except Exception:\n",
        "                        imgs.append(torch.zeros(3, self.config['EVAL_IMG_SIZE'], self.config['EVAL_IMG_SIZE']))\n",
        "                x = torch.stack(imgs, dim=0).to(self.device)\n",
        "                # normalize for feature extractor\n",
        "                x = F.interpolate(x, size=(self.config['EVAL_IMG_SIZE'], self.config['EVAL_IMG_SIZE']), mode='bilinear', align_corners=False)\n",
        "                x = (x - self.preproc.mean) / self.preproc.std\n",
        "                f = self.feature_extractor(x).view(x.size(0), -1).detach().cpu()\n",
        "                feats.append(f)\n",
        "                labels.extend(labs_chunk)\n",
        "                # free\n",
        "                del x, f; torch.cuda.empty_cache()\n",
        "        feats = torch.cat(feats, dim=0).numpy()\n",
        "        labels = np.array(labels, dtype=int)\n",
        "        return feats, labels\n",
        "\n",
        "    # If CSV exists & balanced, load features; otherwise raise error (we assume user already has balanced dataset)\n",
        "    def get_synthetic_features(self):\n",
        "        if not os.path.exists(self.config['SYNTHETIC_CSV_PATH']):\n",
        "            raise RuntimeError(\"Synthetic CSV not found at configured path: \" + self.config['SYNTHETIC_CSV_PATH'])\n",
        "        df = pd.read_csv(self.config['SYNTHETIC_CSV_PATH'])\n",
        "        cnt0 = len(df[df['Pneumonia']==0]); cnt1 = len(df[df['Pneumonia']==1])\n",
        "        if cnt0 < self.config['TARGET_PER_CLASS'] or cnt1 < self.config['TARGET_PER_CLASS']:\n",
        "            raise RuntimeError(f\"Synthetic CSV found but not balanced: ({cnt0},{cnt1})\")\n",
        "        print(f\"‚úÖ Existing balanced synthetic dataset found ({cnt0},{cnt1}). Loading features.\")\n",
        "        return self.load_synthetic_features_from_disk(df)\n",
        "\n",
        "    # Real feature extraction (keeps race)\n",
        "    def extract_real_features_with_race(self):\n",
        "        df = pd.read_csv(self.config['REAL_TEST_CSV']).reset_index(drop=True)\n",
        "        transform = A.Compose([A.Resize(self.config['EVAL_IMG_SIZE'], self.config['EVAL_IMG_SIZE']), A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]), ToTensorV2()])\n",
        "        dataset = RobustRealDatasetWithRace(df, self.config['REAL_IMAGE_DIR'], transform=transform, eval_size=self.config['EVAL_IMG_SIZE'])\n",
        "        loader = DataLoader(dataset, batch_size=self.config['BATCH_SIZE'], shuffle=False, num_workers=self.config['NUM_WORKERS'])\n",
        "        feats = []; labs = []; races = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels, batch_races in tqdm(loader, desc=\"Extracting real features\"):\n",
        "                mask = (labels != -1)\n",
        "                if not mask.any(): continue\n",
        "                imgs_kept = imgs[mask].to(self.device)\n",
        "                labs_kept = labels[mask].cpu().numpy()\n",
        "                races_kept = [r for i,r in enumerate(batch_races) if mask[i]]\n",
        "                f = self.feature_extractor(imgs_kept).view(imgs_kept.shape[0], -1).detach().cpu()\n",
        "                feats.append(f); labs.append(torch.tensor(labs_kept)); races.extend(races_kept)\n",
        "                del imgs_kept, f; torch.cuda.empty_cache()\n",
        "        if len(feats) == 0:\n",
        "            raise RuntimeError(\"No real features extracted.\")\n",
        "        X = torch.cat(feats, dim=0).numpy()\n",
        "        y = torch.cat(labs).numpy()\n",
        "        races = np.array(races, dtype=object)\n",
        "        return X, y, races\n",
        "\n",
        "    # Clinical scoring using Cseg: pass GAN output in [0,1] at 512x512, no ImageNet norm.\n",
        "    def evaluate_clinical_plausibility(self, n_samples=1024):\n",
        "        print(\"\\nü©∫ Calculating Clinical Score (L_area) using Cseg...\")\n",
        "        try:\n",
        "            cseg = smp.Unet('resnet34', in_channels=3, classes=1).to(self.device)\n",
        "            cseg.load_state_dict(torch.load(self.config['CSEG_CHECKPOINT'], map_location=self.device))\n",
        "            cseg.eval()\n",
        "            print(\"‚úÖ Cseg loaded.\")\n",
        "        except Exception as e:\n",
        "            print(\"‚ùå Cseg failed to load:\", e); return None\n",
        "        scores = []\n",
        "        batch = min(self.config['BATCH_SIZE'], 32)\n",
        "        steps = math.ceil(n_samples / batch)\n",
        "        with torch.no_grad():\n",
        "            for _ in range(steps):\n",
        "                z = torch.randn(batch, self.config['LATENT_DIM'], device=self.device)\n",
        "                fake = self.generator(z, alpha=1.0, steps=7)  # [-1,1]\n",
        "                fake_01 = self.preproc.gan_to_01(fake)         # [0,1]\n",
        "                fake_resized = F.interpolate(fake_01, size=(self.config['SEG_IMG_SIZE'], self.config['SEG_IMG_SIZE']), mode='bilinear', align_corners=False)\n",
        "                masks = torch.sigmoid(cseg(fake_resized))\n",
        "                area_pct = masks.sum(dim=[2,3]) / (masks.shape[2] * masks.shape[3])\n",
        "                score = torch.abs(area_pct - self.config['PLAUSIBLE_LUNG_AREA_MEAN']) / self.config['PLAUSIBLE_LUNG_AREA_STD']\n",
        "                scores.append(score.detach().cpu())\n",
        "                del fake, fake_01, fake_resized, masks; torch.cuda.empty_cache()\n",
        "        avg_score = torch.cat(scores).mean().item()\n",
        "        print(f\"   üëâ Clinical L_area Score: {avg_score:.4f}\")\n",
        "        return avg_score\n",
        "\n",
        "    # Fairness metric (TPR per race, EOD)\n",
        "    def compute_fairness_metrics(self, y_true, y_pred, races, min_pos=None):\n",
        "        if min_pos is None: min_pos = self.config['MIN_GROUP_POSITIVES_FOR_TPR']\n",
        "        df = pd.DataFrame({'label': y_true, 'pred': y_pred, 'race': races})\n",
        "        pos_df = df[df['label']==1]\n",
        "        tprs = {}\n",
        "        for r in np.unique(pos_df['race']):\n",
        "            group = pos_df[pos_df['race']==r]\n",
        "            if len(group) < min_pos:\n",
        "                # include small groups if min_pos == 1 (paper setting)\n",
        "                pass\n",
        "            tp = group['pred'].sum()\n",
        "            fn = len(group) - tp\n",
        "            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "            tprs[r] = tpr\n",
        "        if len(tprs) >= 2:\n",
        "            eod = float(max(tprs.values()) - min(tprs.values()))\n",
        "        else:\n",
        "            eod = 0.0\n",
        "        return eod, tprs\n",
        "\n",
        "    # Main run\n",
        "    def run(self):\n",
        "        # 1. Load synthetic (assumes you already have balanced CSV + images)\n",
        "        X_synth, y_synth = self.get_synthetic_features()\n",
        "\n",
        "        # 2. Extract real features (and races)\n",
        "        X_real, y_real, races = self.extract_real_features_with_race()\n",
        "\n",
        "        # 3. Split real into train/test (we test on test only)\n",
        "        idxs = np.arange(len(X_real))\n",
        "        train_idx, test_idx = train_test_split(idxs, test_size=0.3, random_state=42, stratify=y_real)\n",
        "        X_real_train, y_real_train = X_real[train_idx], y_real[train_idx]\n",
        "        X_real_test, y_real_test = X_real[test_idx], y_real[test_idx]\n",
        "        races_test = races[test_idx]\n",
        "\n",
        "        # 4. Classifiers\n",
        "        classifiers = {\n",
        "            'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "            'SVM': SVC(probability=True, random_state=42)\n",
        "        }\n",
        "\n",
        "        results_rows = []\n",
        "        labels = [0,1]\n",
        "\n",
        "        for name, clf in classifiers.items():\n",
        "            # A: Train on Real -> Test on Real\n",
        "            clf_real = clf\n",
        "            clf_real.fit(X_real_train, y_real_train)\n",
        "            if hasattr(clf_real, \"predict_proba\"):\n",
        "                probs_real = clf_real.predict_proba(X_real_test)[:,1]\n",
        "            else:\n",
        "                probs_real = clf_real.decision_function(X_real_test)\n",
        "            preds_real = clf_real.predict(X_real_test)\n",
        "            auc_real = roc_auc_score(y_real_test, probs_real) if len(np.unique(y_real_test))>1 else float('nan')\n",
        "            acc_real = accuracy_score(y_real_test, preds_real)\n",
        "            f1_real = f1_score(y_real_test, preds_real, zero_division=0)\n",
        "            results_rows.append({'Method':'Train on Real','Classifier':name,'AUC':auc_real,'Accuracy':acc_real,'F1':f1_real})\n",
        "\n",
        "            # Save model\n",
        "            if self.config['SAVE_DOWNSTREAM_MODELS']:\n",
        "                outpath = os.path.join(self.config['CLASSIFIER_OUTPUT_DIR'], f\"{name}_trained_on_real.joblib\")\n",
        "                joblib.dump(clf_real, outpath)\n",
        "\n",
        "            # Save confusion matrix for TRTR\n",
        "            cm_path_real = os.path.join(self.config['OUTPUT_DIR'], f\"confmat_{name}_real.png\")\n",
        "            save_confusion_matrix(y_real_test, preds_real, labels, cm_path_real, title=f\"{name} (Train Real)\")\n",
        "\n",
        "            # B: Train on Synthetic -> Test on Real (TSTR)\n",
        "            # Reinit classifier to avoid state carryover\n",
        "            if name == 'LogisticRegression': clf_s = LogisticRegression(max_iter=1000, random_state=42)\n",
        "            elif name == 'RandomForest': clf_s = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "            else: clf_s = SVC(probability=True, random_state=42)\n",
        "\n",
        "            clf_s.fit(X_synth, y_synth)\n",
        "            if hasattr(clf_s, \"predict_proba\"):\n",
        "                probs_synth = clf_s.predict_proba(X_real_test)[:,1]\n",
        "            else:\n",
        "                probs_synth = clf_s.decision_function(X_real_test)\n",
        "            preds_synth = clf_s.predict(X_real_test)\n",
        "            auc_synth = roc_auc_score(y_real_test, probs_synth) if len(np.unique(y_real_test))>1 else float('nan')\n",
        "            acc_synth = accuracy_score(y_real_test, preds_synth)\n",
        "            f1_synth = f1_score(y_real_test, preds_synth, zero_division=0)\n",
        "            results_rows.append({'Method':'Train on Synthetic (TSTR)','Classifier':name,'AUC':auc_synth,'Accuracy':acc_synth,'F1':f1_synth})\n",
        "\n",
        "            # Save model trained on synthetic\n",
        "            if self.config['SAVE_DOWNSTREAM_MODELS']:\n",
        "                outpath = os.path.join(self.config['CLASSIFIER_OUTPUT_DIR'], f\"{name}_trained_on_synth.joblib\")\n",
        "                joblib.dump(clf_s, outpath)\n",
        "\n",
        "            # Save confusion matrix for TSTR\n",
        "            cm_path_synth = os.path.join(self.config['OUTPUT_DIR'], f\"confmat_{name}_synth.png\")\n",
        "            save_confusion_matrix(y_real_test, preds_synth, labels, cm_path_synth, title=f\"{name} (Train Synth)\")\n",
        "\n",
        "            print(f\"   Completed evaluation for {name}.\")\n",
        "\n",
        "        # Save results table\n",
        "        df_res = pd.DataFrame(results_rows)\n",
        "        df_res.to_csv(os.path.join(self.config['OUTPUT_DIR'], 'tstr_trtr_comparison_v4.csv'), index=False)\n",
        "        print(\"\\nüìä Results table saved to:\", os.path.join(self.config['OUTPUT_DIR'], 'tstr_trtr_comparison_v4.csv'))\n",
        "\n",
        "        # Fairness & Clinical summary (use RandomForest trained on synth as primary)\n",
        "        rf_synth_path = os.path.join(self.config['CLASSIFIER_OUTPUT_DIR'], 'RandomForest_trained_on_synth.joblib')\n",
        "        if os.path.exists(rf_synth_path):\n",
        "            rf_synth = joblib.load(rf_synth_path)\n",
        "            preds_rf = rf_synth.predict(X_real_test)\n",
        "        else:\n",
        "            # if not saved, compute from classifier above\n",
        "            preds_rf = classifiers['RandomForest'].predict(X_real_test) if 'RandomForest' in classifiers else np.zeros_like(y_real_test)\n",
        "\n",
        "        eod, tprs = self.compute_fairness_metrics(y_real_test, preds_rf, races_test)\n",
        "        clin_score = self.evaluate_clinical_plausibility(n_samples=1024)\n",
        "\n",
        "        summary = {\n",
        "            'eod': eod,\n",
        "            'tprs': tprs,\n",
        "            'clinical_L_area': clin_score,\n",
        "            'synth_count': len(y_synth)\n",
        "        }\n",
        "        pd.DataFrame([summary]).to_csv(os.path.join(self.config['OUTPUT_DIR'], 'master_v4_summary.csv'), index=False)\n",
        "        print(\"\\n‚úÖ MASTER_v4 complete. Outputs saved to:\", self.config['OUTPUT_DIR'])\n",
        "\n",
        "        return {'results_table': df_res, 'fairness': summary, 'clinical_score': clin_score}\n",
        "\n",
        "# -------------------------\n",
        "# Run main\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    evaluator = MasterEvaluatorV4(CONFIG)\n",
        "    outputs = evaluator.run()\n",
        "    print(outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "import segmentation_models_pytorch as smp\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "#  THE ULTIMATE ROBUST EVALUATOR CLASS\n",
        "# ==========================================\n",
        "\n",
        "class UltimateCAFGANEvaluator:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device(config['DEVICE'])\n",
        "        os.makedirs(config['OUTPUT_DIR'], exist_ok=True)\n",
        "\n",
        "        # Load CSEG for Clinical Score (Lung Area)\n",
        "        print(\"ü©∫ Loading Clinical Segmentation Model...\")\n",
        "        try:\n",
        "            self.cseg = smp.Unet('resnet34', in_channels=3, classes=1).to(self.device)\n",
        "            self.cseg.load_state_dict(torch.load(config['CSEG_CHECKPOINT'], map_location=self.device))\n",
        "            self.cseg.eval()\n",
        "            self.has_cseg = True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not load CSEG: {e}. Clinical scores will be skipped.\")\n",
        "            self.has_cseg = False\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # 1. UTILITY: Train on Synthetic, Test on Real (TSTR)\n",
        "    # -----------------------------------------------------------\n",
        "    def evaluate_utility_tstr(self, X_synth, y_synth, X_real, y_real):\n",
        "        print(\"\\nü§ñ Running Utility Evaluation (TSTR)...\")\n",
        "        # Safety: Reduce CV folds if data is tiny\n",
        "        n_splits = 5\n",
        "        if len(y_real) < 10:\n",
        "            print(\"‚ö†Ô∏è Very small test set. Doing simple train/test.\")\n",
        "            clf = LogisticRegression(max_iter=1000)\n",
        "            clf.fit(X_synth, y_synth)\n",
        "            probs = clf.predict_proba(X_real)[:, 1] if len(np.unique(y_real)) > 1 else np.zeros(len(y_real))\n",
        "            return roc_auc_score(y_real, probs) if len(np.unique(y_real)) > 1 else 0.5\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "        aucs = []\n",
        "        clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "        for _, test_idx in skf.split(X_real, y_real):\n",
        "            X_test_fold = X_real[test_idx]\n",
        "            y_test_fold = y_real[test_idx]\n",
        "\n",
        "            # Train on ALL synthetic data\n",
        "            clf.fit(X_synth, y_synth)\n",
        "\n",
        "            # Predict on Real Fold\n",
        "            if len(np.unique(y_test_fold)) > 1:\n",
        "                probs = clf.predict_proba(X_test_fold)[:, 1]\n",
        "                aucs.append(roc_auc_score(y_test_fold, probs))\n",
        "\n",
        "        mean_auc = np.mean(aucs)\n",
        "        print(f\"   ‚úÖ TSTR Mean AUC: {mean_auc:.4f}\")\n",
        "        return mean_auc\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # 2. PRIVACY/QUALITY: Distinguishability Check\n",
        "    # -----------------------------------------------------------\n",
        "    def evaluate_distinguishability(self, X_real, X_synth):\n",
        "        print(\"\\nüïµÔ∏è Running Distinguishability Check...\")\n",
        "        # SAFE SAMPLING: Don't crash if we have few images\n",
        "        n_samples = min(len(X_real), len(X_synth), 2000)\n",
        "\n",
        "        real_idx = np.random.choice(len(X_real), n_samples, replace=False)\n",
        "        synth_idx = np.random.choice(len(X_synth), n_samples, replace=False)\n",
        "\n",
        "        X_combined = np.vstack([X_real[real_idx], X_synth[synth_idx]])\n",
        "        y_combined = np.array([0] * n_samples + [1] * n_samples) # 0=Real, 1=Fake\n",
        "\n",
        "        clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
        "        clf.fit(X_combined, y_combined)\n",
        "\n",
        "        preds = clf.predict(X_combined)\n",
        "        acc = accuracy_score(y_combined, preds)\n",
        "\n",
        "        print(f\"   ‚úÖ Discriminator Accuracy: {acc:.4f} (0.50 is perfect realism)\")\n",
        "        return acc\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # 3. FAIRNESS: EOD and Demographic Parity\n",
        "    # -----------------------------------------------------------\n",
        "    def evaluate_fairness(self, X_synth, y_synth, X_real, y_real, races):\n",
        "        print(\"\\n‚öñÔ∏è Running Fairness Evaluation...\")\n",
        "        clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        clf.fit(X_synth, y_synth)\n",
        "        preds = clf.predict(X_real)\n",
        "\n",
        "        # Demographic Parity\n",
        "        pos_rates = {}\n",
        "        for r in np.unique(races):\n",
        "            mask = (races == r)\n",
        "            if np.sum(mask) > 0:\n",
        "                pos_rates[r] = np.mean(preds[mask])\n",
        "\n",
        "        dp_diff = (max(pos_rates.values()) - min(pos_rates.values())) if pos_rates else 0.0\n",
        "\n",
        "        # Equalized Odds\n",
        "        tprs = {}\n",
        "        for r in np.unique(races):\n",
        "            mask = (races == r)\n",
        "            if np.sum(mask) > 0:\n",
        "                y_true_g = y_real[mask]\n",
        "                y_pred_g = preds[mask]\n",
        "                if np.sum(y_true_g) > 0:\n",
        "                    tpr = np.sum((y_true_g == 1) & (y_pred_g == 1)) / np.sum(y_true_g == 1)\n",
        "                    tprs[r] = tpr\n",
        "\n",
        "        eod = (max(tprs.values()) - min(tprs.values())) if tprs else 0.0\n",
        "\n",
        "        print(f\"   ‚úÖ Fairness Gap (Demog Parity): {dp_diff:.4f}\")\n",
        "        print(f\"   ‚úÖ Fairness Gap (Equalized Odds): {eod:.4f}\")\n",
        "        return dp_diff, eod\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # 4. CLINICAL: Lung Segmentation Score\n",
        "    # -----------------------------------------------------------\n",
        "    def evaluate_clinical(self, generator, n_samples=100):\n",
        "        if not self.has_cseg: return 0.0\n",
        "        print(\"\\nü©ª Running Clinical Plausibility Check...\")\n",
        "\n",
        "        scores = []\n",
        "        batch_size = 16\n",
        "        steps = n_samples // batch_size\n",
        "\n",
        "        generator.eval()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(steps):\n",
        "                z = torch.randn(batch_size, self.config['LATENT_DIM'], device=self.device)\n",
        "                fake = generator(z, alpha=1.0, steps=7)\n",
        "                fake = (fake + 1) * 0.5 # [-1,1] -> [0,1]\n",
        "\n",
        "                fake_resized = F.interpolate(fake, size=(512, 512), mode='bilinear')\n",
        "                masks = torch.sigmoid(self.cseg(fake_resized))\n",
        "                area = masks.sum(dim=[2,3]) / (512*512)\n",
        "\n",
        "                # Deviation from standard lung area ~0.22\n",
        "                score = torch.abs(area - 0.22)\n",
        "                scores.append(score)\n",
        "\n",
        "        avg_dev = torch.cat(scores).mean().item()\n",
        "        print(f\"   ‚úÖ Clinical Deviation: {avg_dev:.4f} (Lower is better)\")\n",
        "        return avg_dev\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # MASTER RUN\n",
        "    # -----------------------------------------------------------\n",
        "    def run_full_suite(self, X_synth, y_synth, X_real, y_real, races, generator):\n",
        "        tstr_score = self.evaluate_utility_tstr(X_synth, y_synth, X_real, y_real)\n",
        "        dist_score = self.evaluate_distinguishability(X_real, X_synth)\n",
        "        dp_diff, eod_score = self.evaluate_fairness(X_synth, y_synth, X_real, y_real, races)\n",
        "        clin_score = self.evaluate_clinical(generator)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40)\n",
        "        print(\"üèÜ CAF-GAN FINAL SCORECARD\")\n",
        "        print(\"=\"*40)\n",
        "        print(f\"1. Utility (TSTR AUC):      {tstr_score:.4f}  (Target: >0.70)\")\n",
        "        print(f\"2. Realism (Discrim Acc):   {dist_score:.4f}  (Target: ~0.50 best)\")\n",
        "        print(f\"3. Fairness (Demog Diff):   {dp_diff:.4f}  (Target: <0.10)\")\n",
        "        print(f\"4. Fairness (EO Diff):      {eod_score:.4f}  (Target: <0.10)\")\n",
        "        print(f\"5. Clinical (Lung Dev):     {clin_score:.4f}  (Target: <0.10)\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        res = pd.DataFrame([{\n",
        "            'TSTR_AUC': tstr_score,\n",
        "            'Realism_Acc': dist_score,\n",
        "            'Fairness_DP': dp_diff,\n",
        "            'Fairness_EOD': eod_score,\n",
        "            'Clinical_Dev': clin_score\n",
        "        }])\n",
        "        res.to_csv(os.path.join(self.config['OUTPUT_DIR'], \"FINAL_ROBUST_SCORES.csv\"), index=False)\n",
        "        print(f\"Saved to {self.config['OUTPUT_DIR']}/FINAL_ROBUST_SCORES.csv\")\n",
        "\n",
        "# ==========================================\n",
        "# DATA LOADING & EXECUTION (Safe Mode)\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Ensure Evaluator exists\n",
        "    if 'evaluator' not in locals():\n",
        "        print(\"üîÑ Re-initializing MasterEvaluatorV4 to load data...\")\n",
        "        evaluator = MasterEvaluatorV4(CONFIG)\n",
        "\n",
        "    # 2. Explicitly fetch the data into memory now\n",
        "    print(\"üì• Loading Data features...\")\n",
        "    # We assume MasterEvaluatorV4 has these methods (it does in your script)\n",
        "    X_synth, y_synth = evaluator.get_synthetic_features()\n",
        "    X_real, y_real, races = evaluator.extract_real_features_with_race()\n",
        "\n",
        "    # 3. Run Ultimate Suite\n",
        "    ultimate_eval = UltimateCAFGANEvaluator(CONFIG)\n",
        "\n",
        "    ultimate_eval.run_full_suite(\n",
        "        X_synth,\n",
        "        y_synth,\n",
        "        X_real,\n",
        "        y_real,\n",
        "        races,\n",
        "        evaluator.generator\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YvyXpX_6YkP",
        "outputId": "d92c0ee9-87c0-4d3f-eff7-06acc9400068"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading Data features...\n",
            "‚úÖ Existing balanced synthetic dataset found (2500,2500). Loading features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Loading synthetic features:   0%|          | 0/79 [00:00<?, ?it/s]\u001b[A\n",
            "Loading synthetic features:   1%|‚ñè         | 1/79 [00:02<03:51,  2.96s/it]\u001b[A\n",
            "Loading synthetic features:   3%|‚ñé         | 2/79 [00:03<02:05,  1.63s/it]\u001b[A\n",
            "Loading synthetic features:   4%|‚ñç         | 3/79 [00:04<01:32,  1.21s/it]\u001b[A\n",
            "Loading synthetic features:   5%|‚ñå         | 4/79 [00:05<01:15,  1.01s/it]\u001b[A\n",
            "Loading synthetic features:   6%|‚ñã         | 5/79 [00:05<01:06,  1.11it/s]\u001b[A\n",
            "Loading synthetic features:   8%|‚ñä         | 6/79 [00:06<01:01,  1.18it/s]\u001b[A\n",
            "Loading synthetic features:   9%|‚ñâ         | 7/79 [00:07<00:57,  1.25it/s]\u001b[A\n",
            "Loading synthetic features:  10%|‚ñà         | 8/79 [00:07<00:55,  1.28it/s]\u001b[A\n",
            "Loading synthetic features:  11%|‚ñà‚ñè        | 9/79 [00:08<00:53,  1.32it/s]\u001b[A\n",
            "Loading synthetic features:  13%|‚ñà‚ñé        | 10/79 [00:09<00:51,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  14%|‚ñà‚ñç        | 11/79 [00:10<00:50,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  15%|‚ñà‚ñå        | 12/79 [00:10<00:49,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  16%|‚ñà‚ñã        | 13/79 [00:11<00:48,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  18%|‚ñà‚ñä        | 14/79 [00:12<00:49,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  19%|‚ñà‚ñâ        | 15/79 [00:13<00:50,  1.27it/s]\u001b[A\n",
            "Loading synthetic features:  20%|‚ñà‚ñà        | 16/79 [00:14<00:50,  1.24it/s]\u001b[A\n",
            "Loading synthetic features:  22%|‚ñà‚ñà‚ñè       | 17/79 [00:15<00:51,  1.21it/s]\u001b[A\n",
            "Loading synthetic features:  23%|‚ñà‚ñà‚ñé       | 18/79 [00:15<00:48,  1.26it/s]\u001b[A\n",
            "Loading synthetic features:  24%|‚ñà‚ñà‚ñç       | 19/79 [00:16<00:46,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  25%|‚ñà‚ñà‚ñå       | 20/79 [00:17<00:44,  1.32it/s]\u001b[A\n",
            "Loading synthetic features:  27%|‚ñà‚ñà‚ñã       | 21/79 [00:17<00:43,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  28%|‚ñà‚ñà‚ñä       | 22/79 [00:18<00:41,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  29%|‚ñà‚ñà‚ñâ       | 23/79 [00:19<00:41,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  30%|‚ñà‚ñà‚ñà       | 24/79 [00:20<00:40,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  32%|‚ñà‚ñà‚ñà‚ñè      | 25/79 [00:20<00:39,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  33%|‚ñà‚ñà‚ñà‚ñé      | 26/79 [00:21<00:38,  1.39it/s]\u001b[A\n",
            "Loading synthetic features:  34%|‚ñà‚ñà‚ñà‚ñç      | 27/79 [00:22<00:37,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  35%|‚ñà‚ñà‚ñà‚ñå      | 28/79 [00:22<00:36,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  37%|‚ñà‚ñà‚ñà‚ñã      | 29/79 [00:23<00:36,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  38%|‚ñà‚ñà‚ñà‚ñä      | 30/79 [00:24<00:35,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:25<00:34,  1.39it/s]\u001b[A\n",
            "Loading synthetic features:  41%|‚ñà‚ñà‚ñà‚ñà      | 32/79 [00:25<00:35,  1.32it/s]\u001b[A\n",
            "Loading synthetic features:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 33/79 [00:26<00:35,  1.28it/s]\u001b[A\n",
            "Loading synthetic features:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 34/79 [00:27<00:36,  1.24it/s]\u001b[A\n",
            "Loading synthetic features:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 35/79 [00:28<00:35,  1.23it/s]\u001b[A\n",
            "Loading synthetic features:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 36/79 [00:29<00:33,  1.27it/s]\u001b[A\n",
            "Loading synthetic features:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 37/79 [00:29<00:32,  1.29it/s]\u001b[A\n",
            "Loading synthetic features:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 38/79 [00:30<00:31,  1.32it/s]\u001b[A\n",
            "Loading synthetic features:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 39/79 [00:31<00:29,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 40/79 [00:32<00:28,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 41/79 [00:32<00:27,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 42/79 [00:33<00:26,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 43/79 [00:34<00:26,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 44/79 [00:34<00:25,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 45/79 [00:35<00:24,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 46/79 [00:36<00:23,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 47/79 [00:37<00:23,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 48/79 [00:37<00:22,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 49/79 [00:38<00:22,  1.31it/s]\u001b[A\n",
            "Loading synthetic features:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 50/79 [00:39<00:23,  1.26it/s]\u001b[A\n",
            "Loading synthetic features:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 51/79 [00:40<00:22,  1.22it/s]\u001b[A\n",
            "Loading synthetic features:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 52/79 [00:41<00:22,  1.19it/s]\u001b[A\n",
            "Loading synthetic features:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 53/79 [00:42<00:21,  1.24it/s]\u001b[A\n",
            "Loading synthetic features:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 54/79 [00:42<00:19,  1.28it/s]\u001b[A\n",
            "Loading synthetic features:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 55/79 [00:43<00:18,  1.31it/s]\u001b[A\n",
            "Loading synthetic features:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 56/79 [00:44<00:17,  1.33it/s]\u001b[A\n",
            "Loading synthetic features:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/79 [00:44<00:16,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:45<00:15,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:46<00:14,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 60/79 [00:47<00:13,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/79 [00:47<00:13,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 62/79 [00:48<00:12,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:49<00:11,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:50<00:10,  1.38it/s]\u001b[A\n",
            "Loading synthetic features:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 65/79 [00:50<00:10,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 66/79 [00:51<00:09,  1.36it/s]\u001b[A\n",
            "Loading synthetic features:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 67/79 [00:52<00:09,  1.30it/s]\u001b[A\n",
            "Loading synthetic features:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 68/79 [00:53<00:08,  1.28it/s]\u001b[A\n",
            "Loading synthetic features:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 69/79 [00:54<00:08,  1.24it/s]\u001b[A\n",
            "Loading synthetic features:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 70/79 [00:54<00:07,  1.25it/s]\u001b[A\n",
            "Loading synthetic features:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 71/79 [00:55<00:06,  1.28it/s]\u001b[A\n",
            "Loading synthetic features:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 72/79 [00:56<00:05,  1.31it/s]\u001b[A\n",
            "Loading synthetic features:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 73/79 [00:57<00:04,  1.33it/s]\u001b[A\n",
            "Loading synthetic features:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 74/79 [00:57<00:03,  1.34it/s]\u001b[A\n",
            "Loading synthetic features:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 75/79 [00:58<00:02,  1.35it/s]\u001b[A\n",
            "Loading synthetic features:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 76/79 [00:59<00:02,  1.37it/s]\u001b[A\n",
            "Loading synthetic features:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 77/79 [00:59<00:01,  1.37it/s]\u001b[A\n",
            "Loading synthetic features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [01:00<00:00,  1.30it/s]\n",
            "\n",
            "Extracting real features:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Extracting real features:  10%|‚ñà         | 1/10 [00:03<00:28,  3.20s/it]\u001b[A\n",
            "Extracting real features:  20%|‚ñà‚ñà        | 2/10 [00:03<00:11,  1.42s/it]\u001b[A\n",
            "Extracting real features:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:07<00:18,  2.71s/it]\u001b[A\n",
            "Extracting real features:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:07<00:10,  1.71s/it]\u001b[A\n",
            "Extracting real features:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:10<00:10,  2.11s/it]\u001b[A\n",
            "Extracting real features:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:10<00:05,  1.45s/it]\u001b[A\n",
            "Extracting real features:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:13<00:05,  1.88s/it]\u001b[A\n",
            "Extracting real features:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:13<00:02,  1.32s/it]\u001b[A\n",
            "Extracting real features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:15<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü©∫ Loading Clinical Segmentation Model...\n",
            "\n",
            "ü§ñ Running Utility Evaluation (TSTR)...\n",
            "   ‚úÖ TSTR Mean AUC: 0.6308\n",
            "\n",
            "üïµÔ∏è Running Distinguishability Check...\n",
            "   ‚úÖ Discriminator Accuracy: 1.0000 (0.50 is perfect realism)\n",
            "\n",
            "‚öñÔ∏è Running Fairness Evaluation...\n",
            "   ‚úÖ Fairness Gap (Demog Parity): 0.2857\n",
            "   ‚úÖ Fairness Gap (Equalized Odds): 0.5000\n",
            "\n",
            "ü©ª Running Clinical Plausibility Check...\n",
            "   ‚úÖ Clinical Deviation: 0.1314 (Lower is better)\n",
            "\n",
            "========================================\n",
            "üèÜ CAF-GAN FINAL SCORECARD\n",
            "========================================\n",
            "1. Utility (TSTR AUC):      0.6308  (Target: >0.70)\n",
            "2. Realism (Discrim Acc):   1.0000  (Target: ~0.50 best)\n",
            "3. Fairness (Demog Diff):   0.2857  (Target: <0.10)\n",
            "4. Fairness (EO Diff):      0.5000  (Target: <0.10)\n",
            "5. Clinical (Lung Dev):     0.1314  (Target: <0.10)\n",
            "========================================\n",
            "Saved to /content/drive/MyDrive/CAF-GAN/outputs/evaluation_results_master_v4//FINAL_ROBUST_SCORES.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}